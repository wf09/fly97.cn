<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>个人随想</title>
  
  
  <link href="https://fly97.cn/atom.xml" rel="self"/>
  
  <link href="https://fly97.cn/"/>
  <updated>2020-10-11T12:00:00.000Z</updated>
  <id>https://fly97.cn/</id>
  
  <author>
    <name>个人随想</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>现代信号分析第二章作业</title>
    <link href="https://fly97.cn/p/%E7%8E%B0%E4%BB%A3%E4%BF%A1%E5%8F%B7%E5%88%86%E6%9E%90%E7%AC%AC%E4%BA%8C%E7%AB%A0%E4%BD%9C%E4%B8%9A.html"/>
    <id>https://fly97.cn/p/%E7%8E%B0%E4%BB%A3%E4%BF%A1%E5%8F%B7%E5%88%86%E6%9E%90%E7%AC%AC%E4%BA%8C%E7%AB%A0%E4%BD%9C%E4%B8%9A.html</id>
    <published>2020-10-11T12:00:00.000Z</published>
    <updated>2020-10-11T12:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong>此系列文章是我从2020年9月21日开始在浙江理工大学读研一时《现代信号分析》课后作业练习题及答案。</p><p><strong>关键词：</strong>研一，现代信号分析</p><a id="more"></a><p><img src="https://ftp.fly97.cn/image/image-20200928193703316.png" alt="image-20200928193703316"></p><p><img src="https://ftp.fly97.cn/image/image-20201011203228683.png" alt="image-20201011203228683"></p><p><img src="https://ftp.fly97.cn/image/image-20201011203330808.png" alt="image-20201011203330808"></p><p><img src="https://ftp.fly97.cn/image/image-20200928193714036.png" alt="image-20200928193714036"></p><p><img src="https://ftp.fly97.cn/image/image-20201011203626045.png" alt="image-20201011203626045"></p><p><img src="https://ftp.fly97.cn/image/image-20201011203639917.png" alt="image-20201011203639917"></p><p><img src="https://ftp.fly97.cn/image/image-20201011203658032.png" alt="image-20201011203658032"></p><p><img src="https://ftp.fly97.cn/image/image-20201011203716172.png" alt="image-20201011203716172"></p><p><img src="https://ftp.fly97.cn/image/image-20201011203748238.png" alt="image-20201011203748238"></p><p><img src="https://ftp.fly97.cn/image/image-20201011203823320.png" alt="image-20201011203823320"></p><p><img src="https://ftp.fly97.cn/image/image-20201011203917101.png" alt="image-20201011203917101"></p><p><img src="https://ftp.fly97.cn/image/image-20201011203848593.png" alt="image-20201011203848593"></p><p><img src="https://ftp.fly97.cn/image/image-20200928193737091.png" alt="image-20200928193737091"></p><p><img src="https://ftp.fly97.cn/image/image-20201011204004991.png" alt="image-20201011204004991"></p><p><img src="https://ftp.fly97.cn/image/image-20201011204054961.png" alt="image-20201011204054961"></p><p><img src="https://ftp.fly97.cn/image/image-20201011204157647.png" alt="image-20201011204157647"></p><p><img src="https://ftp.fly97.cn/image/image-20200928193754540.png" alt="image-20200928193754540"></p><p><img src="https://ftp.fly97.cn/image/image-20201011204330872.png" alt="image-20201011204330872"></p><p><img src="https://ftp.fly97.cn/image/image-20201011204359072.png" alt="image-20201011204359072"></p><p><img src="https://ftp.fly97.cn/image/image-20201011204438075.png" alt="image-20201011204438075"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;此系列文章是我从2020年9月21日开始在浙江理工大学读研一时《现代信号分析》课后作业练习题及答案。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词：&lt;/strong&gt;研一，现代信号分析&lt;/p&gt;</summary>
    
    
    
    
    <category term="研一" scheme="https://fly97.cn/tags/%E7%A0%94%E4%B8%80/"/>
    
    <category term="现代信号分析" scheme="https://fly97.cn/tags/%E7%8E%B0%E4%BB%A3%E4%BF%A1%E5%8F%B7%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>ROS系统学习小记(一)</title>
    <link href="https://fly97.cn/p/ROS%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0.html"/>
    <id>https://fly97.cn/p/ROS%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0.html</id>
    <published>2020-09-23T12:46:25.000Z</published>
    <updated>2020-09-23T12:46:25.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>概述：</strong>以下是作者与2020年9月23日起在浙江理工大学读研究生一年级时研究ROS实时系统时的笔记。希望能帮到你。</p><p><strong>关键词：</strong>ROS</p><a id="more"></a><h3 id="ROS架构及概念"><a href="#ROS架构及概念" class="headerlink" title="ROS架构及概念"></a>ROS架构及概念</h3><p>ROS的架构经过设计并划分为三部分，每一部分都代表一个层级的概念：</p><ul><li>文件系统级（Filesystem level)</li><li>计算图级(Computation Graph level)</li><li>社区级(Community level)</li></ul><p>第一级是文件系统级。在这一级，我们会使用一组概念来解释ROS的内部构成、文件夹结构，以及工作所需要的核心文件。</p><p>第二级是计算图级，体现的是进程和系统之间的通信。在相关小节中，我们将学习ROS的各个概念和功能，包括建立系统、处理各类进程、与多台机器通信等。</p><p>第三级是社区级，我们将解释一系列的工具和概念，包括在开发人员之间如何共享知识、算法和代码。由于强大社区的支持，不仅提高了初学者理解复杂软件的能力，还解决了最常见的问题。</p><h4 id="理解ROS文件系统级"><a href="#理解ROS文件系统级" class="headerlink" title="理解ROS文件系统级"></a>理解ROS文件系统级</h4><p><img src="/home/wsl/.config/Typora/typora-user-images/image-20200923190637341.png" alt="image-20200923190637341"></p><p>与其他操作系统类似，一个ROS程序的不同组件要放在不同的文件夹下，这些文件夹是根据功能的不同来对文件进行组织的。</p><ol><li>功能包（Package）：功能包构成ROS中的原子级。一个功能包具有创建ROS程序最小结构和最少内容。它可以包含ROS运行时进程（节点）、配置文件等。</li><li>功能包清单（Package Manifest）：功能包清单提供关于功能包、许可证、依赖关系、编译标志等的信息。包清单又一个名为<strong>package.xml</strong>的文件管理。</li><li>元功能包（Metapackage）：如果你希望将几个具有<strong>某些功能的包组织在一起</strong>，那么你将使用一个元功能包。这种包的组织形式<strong>之前被称</strong>为功能包集（Stack ）。功能包集被废除，现在使用元功能包实现这个功能。在ROS中，存在大量不同用途的元功能包，例如<strong>导航功能包集</strong>。</li><li>元功能包清单（Metapackage manifest）：元功能包清单（package.xml）类似普通功能包但又一个XML格式的导出标记，他在结构上也有一定的限制。</li><li>消息类型（Message（msg）type）：消息是一个进程发送到其他进程的消息。ROS 的消息类型的说明存储在<strong>my_package/msg/MyMessageType.msg</strong>中。</li><li>服务类型（Service (srv) Type）：服务描述说明存储在<strong>my_package/srv/MyServiceType.srv</strong>中，为ROS中由每个进程提供的服务定义请求和响应数据结构。</li></ol><p>下面的截图说明了<strong>turtlesim</strong>功能包的内容。所看到的是一系列文件和文件夹，包含代码、图片、启动文件服务和消息。以下只是文件的一个简短列表。</p><p><img src="/home/wsl/.config/Typora/typora-user-images/image-20200923193232140.png" alt="image-20200923193232140"></p><h5 id="工作空间"><a href="#工作空间" class="headerlink" title="工作空间"></a>工作空间</h5><p>工作空间包含功能包，功能包包含源文件和环境和工作空间，是集中开发的一种好方式。</p><p>下图所示是一个典型的工作空间。<img src="/home/wsl/.config/Typora/typora-user-images/image-20200924144159317.png" alt="image-20200924144159317"></p><p>主要包含一下内容：</p><ul><li>源文件空间（Source space）：在源空间（src文件夹）中，放置了功能包、项目、复制的包等。<strong>最重要文件：CMakeLists.txt</strong>。当在工作空间配置包时，通过cmake调用CMakeLists.txt。这个文件是通过<strong>catkin_init_workspace</strong>命令创建的。</li><li>编译空间（build space）：在build文件夹里，cmake和catkin为功能包和项目保存缓存信息、配置和其他中间文件。</li><li>开发空间（Development （devel）space）：devel文件夹用来保存编译后的程序，这些是无需安装就能用来测试的程序。</li></ul><p>用catkin编译包有两个选项。第一个是使用标准CMake工作流程。通过使用此方式。可以一次编译一个包，见以下命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmake packageToBuild/</span><br><span class="line">make</span><br></pre></td></tr></table></figure><p>如果想编译所有的包，可以用<strong>catkin_make</strong>命令行，见以下命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> workspace</span><br><span class="line">catkin_make</span><br></pre></td></tr></table></figure><p>在ROS配置的编译空间目录中，这两个命令编译出可执行文件。</p><p>ROS支持覆盖（overlay）。当你正在使用ROS功能包例如（<strong>Turtlesim</strong>）时，可以使用安装版本，也可以下载源文件并编译它来使用你修改后的版本。</p><p>ROS允许使用自己版本的功能包去替代安装版本。下一章我们将使用这个功能来创建自己的插件。</p><h5 id="功能包"><a href="#功能包" class="headerlink" title="功能包"></a>功能包</h5><p>包指的是一种特定结构的文件和文件夹组合。</p><table><thead><tr><th>目录</th><th>功能</th></tr></thead><tbody><tr><td>include/package_name</td><td>此目录包含了需要的库的头文件</td></tr><tr><td>msg/</td><td>如果开发需要<strong>非标准</strong>的消息，请把文件放在这里。</td></tr><tr><td>script/</td><td>其中包含Bash、Python或者任何其他脚本语言的可执行脚本。</td></tr><tr><td>src/</td><td>存储程序源文件。可以为节点创建一个文件夹或按照希望的方式组织它。</td></tr><tr><td>srv/</td><td>（srv）服务类型</td></tr><tr><td>CMakeLists.txt</td><td>CMake的生成文件</td></tr><tr><td>package.xml</td><td>功能包清单文件</td></tr></tbody></table><p>ROS提供的工具（命令）</p><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>rospack</td><td>使用此命令来获取信息或在系统中查找包</td></tr><tr><td>catkin_create_pkg</td><td>使用此命令创建一个新的功能包</td></tr><tr><td>catin_make</td><td>使用此命令来编译工作空间</td></tr><tr><td>rosdep</td><td>使用此命令按照功能包的系统依赖项</td></tr><tr><td>rqt_dep</td><td>使用此命令来查看包的依赖关系图</td></tr></tbody></table><p>如果要在文件夹和功能包之间移动文件，ROS提供了非常有用的<strong>rosbash</strong>，功能包，其中包含的非常类似Linux命令的命令。</p><table><thead><tr><th>命令</th><th>功能</th></tr></thead><tbody><tr><td>roscd</td><td>此命令用于更改目录，相当于Linux中的cd命令</td></tr><tr><td>rosed</td><td>此命令用来编辑文件</td></tr><tr><td>roscp</td><td>此命令用于从功能包复制文件。</td></tr><tr><td>rosls</td><td>此命令列出功能包下的文件，类似Linux中的ls命令。</td></tr></tbody></table><p>文件<strong>package.xml</strong>必须在每个功能包中，它用来说明此包相关的各类信息。如果你发现在某个文件夹内包含此文件，那么这个文件夹很可能是<strong>一个包或者元功能包</strong>。</p><p>打开<strong>package.xml</strong>文件，可以看到包的名称、依赖关系等信息。功能包清单的作用就是为了方便安装和分发这些功能包。</p><p>在<strong>package.xml</strong>文件中使用的两个典型标记是**<build_depend><strong>和</strong><run_depend>**.</p><p>**<build_depend>**标记会显示当前功能包安装之前必须先安装哪些功能包。这是因为新的功能包会使用其他包的一些功能。</p><p>**<run_depend>**标记显示运行功能包中代码所需要的包。以下是package.xml文件的示例。</p><p><img src="/home/wsl/.config/Typora/typora-user-images/image-20200924154802735.png" alt="image-20200924154802735"></p><h5 id="元功能包"><a href="#元功能包" class="headerlink" title="元功能包"></a>元功能包</h5><p>元包中只有一个文件，这个文件就是<strong>package.xml</strong>。它不包含其他文件，如代码等。</p><p>元功能包用于指代其他按照类似功能特性分组的包，例如导航功能包集，ros_tutorials等。</p><p>使用迁移的特定规则，可以讲ROS Fuerte中的功能包和功能包集转换为Kinetic等。具体参见<a href="http://wiki.ros.org/catkin/migrating_from_rosbuild%E3%80%82">http://wiki.ros.org/catkin/migrating_from_rosbuild。</a></p><p>在下图中。可以看到在ros_tutorials元功能包中package.xml的内容。可以看到<br>&lt;export&gt;标记和&lt;run_depend&gt;标记。这些事功能包清单中必不可缺少的，在下图中也可以看到这些标记。</p><p><img src="/home/wsl/.config/Typora/typora-user-images/image-20200924160401768.png" alt="image-20200924160401768"></p><p>如果你想定位<strong>ros_tutorials</strong>元功能包，可以使用下面的命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rosstack find ros_tutorials</span><br></pre></td></tr></table></figure><p>显示路径为：</p><p><img src="/home/wsl/.config/Typora/typora-user-images/image-20200924161034651.png" alt="image-20200924161034651"></p><p>查看里面的代码</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/ros/kinetic/share/ros_tutorials/package.xml</span><br></pre></td></tr></table></figure><p>注意：Kinetic使用元功能包，不是功能包集，但是<strong>rosstack find</strong> 命令也可以用于查找元功能包。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;概述：&lt;/strong&gt;以下是作者与2020年9月23日起在浙江理工大学读研究生一年级时研究ROS实时系统时的笔记。希望能帮到你。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词：&lt;/strong&gt;ROS&lt;/p&gt;</summary>
    
    
    
    
    <category term="ROS" scheme="https://fly97.cn/tags/ROS/"/>
    
  </entry>
  
  <entry>
    <title>Python科学计算库Numpy</title>
    <link href="https://fly97.cn/p/Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%BA%93Numpy.html"/>
    <id>https://fly97.cn/p/Python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%BA%93Numpy.html</id>
    <published>2020-09-20T07:00:00.000Z</published>
    <updated>2020-09-20T07:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>摘要：</strong>Numpy是一个开源的Python科学计算库，它是Python科学计算库的基础库，许多其他著名的科学计算库如Pandas、Scikit-learn等，都要用的Numpy库的一些功能。</p><p><strong>关键词：</strong>科学计算，Numpy</p><a id="more"></a><p>Numpy是Python快速处理大型矩阵的科学计算库，Numpy允许你在Python中做向量矩阵的运算，而且很多底层的函数都是用C语言写的，将获得在普通Python中无法达到的运算速度。</p><p>什么是科学计算？科学计算是一个与定量分析、数学模型构建以及利用计算机分析和解决科学问题相关的相关领域。<br><strong>查看Numpy版本</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import numpy</span><br><span class="line"></span><br><span class="line">print(numpy.__version__)</span><br></pre></td></tr></table></figure><p><img src="C:\Users\wf09\AppData\Roaming\Typora\typora-user-images\image-20200920154143301.png" alt="image-20200920154143301"></p><h3 id="初识Numpy"><a href="#初识Numpy" class="headerlink" title="初识Numpy"></a>初识Numpy</h3><p><strong>Numpy</strong>的主要对象是同质多维数组，也就是在一个元素(通常是数字)表中，元素的类型都是相同的，其中可以通过正整数的元组来对元素进行索引。</p><p>在Numpy中，数组的维度被称为轴(axes)，轴的数量被称为秩(rank)。例如在三维空间中一个点的坐标【1，2，1】就是秩为1的数组，因为它只有一个轴，这个轴的长度为3。</p><p><strong>Numpy</strong>的数组类称为<strong>ndarray</strong>，别名为array。<strong>numpy.array</strong>与标准Python库类<strong>array.array</strong>不同。标准库类中只能处理一维数组而且功能相对较少。下面我们来认识下<strong>ndarray</strong>对象的常见属性。</p><table><thead><tr><th>属性</th><th>含义</th></tr></thead><tbody><tr><td>T</td><td>转置，与self.transpose()相同，如果维度小于2，返回self</td></tr><tr><td>size</td><td>数组中元素个数，等于shape元素的乘积</td></tr><tr><td>itemsize</td><td>一个类型为float64的元素的数组itemsize为8=(64/8)，而一个complex32的数组itersize为4=(32/8). 该属性等价于ndarray.dtype.itemsize</td></tr><tr><td>dtype</td><td>数组元素的数据类型对象。可以用标准Python类型来创建或指定dtype，或者在后面加上Numpy的类型：numpy.int32，numpy.int16，numpy.float64等等</td></tr><tr><td>ndim</td><td>数组的轴（维度）的数量。在Python中，维度的数量通常被称为rank</td></tr><tr><td>shape</td><td>数组的维度，为一个整数元组。表示每个维度上的大小。对于一个m行n列的矩阵来说，shape就是(n, m)</td></tr><tr><td>data</td><td>该缓冲区中包含了数组的实际元素，通常情况下不需要使用这个属性因为我们会使用<strong>索引</strong>的方式来访问数组中的元素。</td></tr><tr><td>Flat</td><td>返回数组的一维迭代器</td></tr><tr><td>imag</td><td>返回数组的虚部</td></tr><tr><td>real</td><td>返回数组的实部</td></tr><tr><td>nbytes</td><td>数组中所有元素的字节长度</td></tr></tbody></table><p>示例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.random.random(<span class="number">4</span>)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><p><img src="C:\Users\wf09\AppData\Roaming\Typora\typora-user-images\image-20200920164603559.png" alt="image-20200920164603559"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(a.shape)</span><br></pre></td></tr></table></figure><p><img src="C:\Users\wf09\AppData\Roaming\Typora\typora-user-images\image-20200920164658559.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(type(a))</span><br></pre></td></tr></table></figure><p><img src="C:\Users\wf09\AppData\Roaming\Typora\typora-user-images\image-20200920165038789.png" alt="image-20200920165038789"></p><p>以上说明，通过np.random.random(4)生成的一个浮点数组，类型为numpy.ndarray，a.shape显示的<strong>长度</strong>为4。</p><p>【这里的数组可以理解为一维数组】</p><h3 id="Numpy数据类型"><a href="#Numpy数据类型" class="headerlink" title="Numpy数据类型"></a>Numpy数据类型</h3><p>对于科学计算来说，Python自带的整型，浮点数和复数类型还远远不够。因此Numpy添加了许多数据类型， 在实际应用中，我们需要不同精度的数据类型，它们占用的内存空间也是不同的，在numpy中，大部分数据类型是以数字结尾的，这个数字表示其在内存中占用的位数。</p><table><thead><tr><th>类型</th><th>描述规则</th></tr></thead><tbody><tr><td>bool</td><td>用一位存储的bool类型</td></tr><tr><td>inti</td><td>由所在平台决定其精度的整数（一般为int32或者int64）</td></tr><tr><td>int8</td><td>整数，范围为-128至127</td></tr><tr><td>int16</td><td>整数，范围为-32768至32767</td></tr><tr><td>int32</td><td>整数，范围为-2^31至2^31-1</td></tr><tr><td>int64</td><td>整数，范围为-2^63至2^63</td></tr><tr><td>uint8</td><td>无符号整数，范围为0至255</td></tr><tr><td>uint16</td><td>无符号整数，范围为0至65535</td></tr><tr><td>uint32</td><td>无符号整数，范围为0至2^32-1</td></tr><tr><td>uint64</td><td>无符号整数，范围为0至2^64</td></tr><tr><td>float16</td><td>半精度浮点数(16位)，其中一位表示正负号，5位表示指数，10位表示尾数</td></tr><tr><td>float32</td><td>单精度浮点数(32位)，其中一位表示正负号，8位表示指数，23位表示尾数</td></tr><tr><td>float64或float</td><td>双精度浮点数(64位)，其中一位表示正负号，11位表示指数，52位表示位数</td></tr><tr><td>complex64</td><td>复数，分别用两个32位浮点数表示实部和虚部</td></tr><tr><td>complex128或complex</td><td>复数，分别用两个64位浮点数表示实部和虚部</td></tr></tbody></table><p>在使用numpy过程中，可以通过dtype来指定数据类型，通常这个参数是可选的。也可以通过astype()来指定。同样，每一种数据类型均有对应的类型转换函数。在Python中，通常不要求内存控制指定。</p><p><strong>Numpy数据类型操作</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定数据类型</span></span><br><span class="line">print(np.array(<span class="number">5</span>, dtype = int))</span><br><span class="line"></span><br><span class="line">print(np.array(<span class="number">5</span>).astype(float))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换数据类型</span></span><br><span class="line">print(float(<span class="number">42</span>))</span><br><span class="line"></span><br><span class="line">print(bool(<span class="number">42</span>))</span><br><span class="line"></span><br><span class="line">print(float(<span class="literal">True</span>))</span><br></pre></td></tr></table></figure><p><img src="C:\Users\wf09\AppData\Roaming\Typora\typora-user-images\image-20200920182149479.png" alt="image-20200920182149479"></p><p><strong>查看Numpy数据类型</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(set(np.typeDict.values()))</span><br></pre></td></tr></table></figure><p><img src="C:\Users\wf09\AppData\Roaming\Typora\typora-user-images\image-20200920182353862.png" alt="image-20200920182353862"></p><h3 id="Numpy创建数组"><a href="#Numpy创建数组" class="headerlink" title="Numpy创建数组"></a>Numpy创建数组</h3><h4 id="通过列表或者元组转化"><a href="#通过列表或者元组转化" class="headerlink" title="通过列表或者元组转化"></a>通过列表或者元组转化</h4><p>在Python内建对象中，数组有三种形式：列表（list）、元组（tuple）、字典（dict）。具体形式如下：</p><ul><li>list: [1, 2, 3]</li><li>tuple: (1, 2, 3)</li><li>dict: {a:1, b:2}</li></ul><p>使用np.array将<strong>列表或元组</strong>转换成narray数组。其方法为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.array(object, dtype=<span class="literal">None</span>, copy=<span class="literal">True</span>, </span><br><span class="line">         order=<span class="string">&#x27;K&#x27;</span>, subook= <span class="literal">False</span>, ndmin=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>相关参数如下：</p><ul><li>object：输入对象列表、元组等。</li><li>dtype：数据类型。如果没有给出，则类型被保存为所需对象的最小类型。</li><li>copy：布尔类型，默认为<strong>True</strong>，表示复制对象。</li><li>order：顺序。</li><li>subok：布尔类型，表示子类是否被传递。</li></ul><p><strong>使用np.array创建数组</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>],[<span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>]])</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;a:&#123;&#125;, type of a:&#123;&#125;&quot;</span>.format(a, type(a)))</span><br></pre></td></tr></table></figure><p><img src="C:\Users\wf09\AppData\Roaming\Typora\typora-user-images\image-20200920184454753.png" alt="image-20200920184454753"></p><h4 id="arange函数创建数组"><a href="#arange函数创建数组" class="headerlink" title="arange函数创建数组"></a>arange函数创建数组</h4><p>np.arange()的功能是在给定区间内创建<strong>等差数组</strong>。arange类似range函数，接触过Python的人或许对range函数比较熟悉。例如在for循环中，经常用到range。下面通过range来学习arange，主要区别是<strong>返回值类型不同</strong>。</p><p>range返回的是list，np.arange返回的是narray数组。</p><ol><li>range函数为 range(start, stop[, step])，根据start和stop指定的范围以及step设定的步长，生成一个序列，函数返回的是一个range object。这里的[start, stop]是一个<strong>前闭后开</strong>区间。</li></ol><ul><li>start：计数从start开始，默认是从0开始，例如range(5)等价于range(0, 5)</li><li>stop：计数从stop结束，但不包括stop，例如range(0, 5)=[0, 1, 2, 3, 4]</li><li>step：每次跳跃的间距，默认为1且<strong>不支持步长为小数</strong>，例如range(0, 5)等价于range(0, 5, 1)</li></ul><p>案例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = range(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line">b = range(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">a1 = [i <span class="keyword">for</span> i <span class="keyword">in</span> a]</span><br><span class="line">b1 = [i <span class="keyword">for</span> i <span class="keyword">in</span> b]</span><br><span class="line">print(<span class="string">&quot;type of a:&#123;0&#125;, a:&#123;1&#125;, b:&#123;2&#125;,  a1:&#123;3&#125;, b1:&#123;4&#125;&quot;</span>.format(type(a), a, b, a1, b1))</span><br></pre></td></tr></table></figure><p><img src="C:\Users\wf09\AppData\Roaming\Typora\typora-user-images\image-20200920190839464.png" alt="image-20200920190839464"></p><ol start="2"><li>arange函数为arange(start=None, stop=None, step=None, dtype=None), 根据<strong>start</strong>与<strong>stop</strong>指定的范围以及<strong>step</strong>设定的步长，生成一个<strong>ndarry</strong></li></ol><ul><li>start与stop参数同range。</li><li>step：步长用于设置值之间的间隔，支持<strong>步长为小数</strong>。</li><li>dtype：可选参数，可以设置返回ndarray的值类型。</li></ul><p><strong>arange案例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">a2 = np.arange(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;a:&#123;&#125;,a2:&#123;&#125;&quot;</span>.format(a,a2))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="C:\Users\wf09\AppData\Roaming\Typora\typora-user-images\image-20200920191959047.png" alt="image-20200920191959047"></p><h4 id="linspace生成等差数列"><a href="#linspace生成等差数列" class="headerlink" title="linspace生成等差数列"></a>linspace生成等差数列</h4><p>np.linspace方法也可以像np.arange方法一样，创建数值有规律的数组。linespace用于在指定区域返回间隔均匀的值，其方法为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.linespace(start, stop, num=<span class="number">50</span>, endpoint=<span class="literal">True</span>, restep=<span class="literal">False</span>, dtype=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><ul><li>start：序列的起始值。</li><li>stop：序列的结束值。</li><li>num：生成的样本数，默认为50。</li><li>endpoint：布尔值，若为True，则最后一个样本包含在序列内。</li><li>restep：布尔值，若为True，返回间距。</li><li>dtype：数组的类型。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;Numpy是一个开源的Python科学计算库，它是Python科学计算库的基础库，许多其他著名的科学计算库如Pandas、Scikit-learn等，都要用的Numpy库的一些功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词：&lt;/strong&gt;科学计算，Numpy&lt;/p&gt;</summary>
    
    
    
    
    <category term="Numpy" scheme="https://fly97.cn/tags/Numpy/"/>
    
  </entry>
  
  <entry>
    <title>NLTK简介</title>
    <link href="https://fly97.cn/p/NLTK%E7%AE%80%E4%BB%8B.html"/>
    <id>https://fly97.cn/p/NLTK%E7%AE%80%E4%BB%8B.html</id>
    <published>2020-09-17T11:43:00.000Z</published>
    <updated>2020-09-17T11:43:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要介绍了NLTK语言工具包。</p><p><strong>摘要：</strong>自然语言处理（NLP）是计算机科学领域与人工智能的一个重要方向。他研究实现人与计算机之间用自然语言进行有效的通信的各种领域和方法，涉及所有用计算机对自然语言处理进行的操作。以下例子是基于Python语言和一个名为NLTK的自然语言工具包的开源库实现的。</p><p><strong>关键词：</strong>自然语言处理，NLP，NLTK</p><a id="more"></a><p>NLTK创建于2001年，最初是宾夕法尼亚州立大学计算机与信息科学系计算语言学课程的一部分。从那以后，在数十名贡献者的帮助下不断发展壮大，如今，它已被数十所大学的课程所采纳，并作为许多项目研究的基础。</p><h3 id="第一章-语言处理与Python"><a href="#第一章-语言处理与Python" class="headerlink" title="第一章 语言处理与Python"></a>第一章 语言处理与Python</h3><p>提出问题：</p><ol><li>通过将技术性较为简单的程序与大规模文本结合起来，我们能实现什么？</li><li>如何自动的提取处关键字和词组，用来总结文本的风格和内容？</li><li>Python编程语言为上述工作提供了哪些工具和技术？</li><li>自然语言处理中有哪些有趣的挑战呢？</li></ol><h4 id="语言计算：文本和词汇"><a href="#语言计算：文本和词汇" class="headerlink" title="语言计算：文本和词汇"></a>语言计算：文本和词汇</h4><h5 id="安装nltk"><a href="#安装nltk" class="headerlink" title="安装nltk"></a>安装nltk</h5><p>使用pip进行安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install nltk</span><br></pre></td></tr></table></figure><p>输入以下命令来安装数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> nltk</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nltk.download()</span><br></pre></td></tr></table></figure><p>或者直接点击以下链接进行下载：<a href="https://github.com/nltk/nltk_data/archive/gh-pages.zip">点击下载</a></p><p>这里使用第二种方法。</p><p>下载完毕以后得到如图所示的压缩文件</p><p><img src="https://ftp.fly97.cn/image/image-20200917210303624.png" alt="image-20200917210303624"></p><p>解压并打开文件夹</p><p><img src="https://ftp.fly97.cn/image/image-20200917210405366.png" alt="image-20200917210405366"></p><p>打开packages，复制路径，添加<code>NLTK_DATA</code>到环境变量</p><p><img src="https://ftp.fly97.cn/image/image-20200917210518955.png" alt="image-20200917210518955"></p><p>测试是否安装成功</p><p><img src="https://ftp.fly97.cn/image/image-20200917210938768.png" alt="image-20200917210938768"></p><p>输入以下命令加载一些我们需要的文本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.book <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200917211222091.png" alt="image-20200917211222091"></p><p>无论什么时候想要找到这些文本，只需要在Python提示符后面输入它的名字即可</p><p><img src="https://ftp.fly97.cn/image/image-20200917211343198.png" alt="image-20200917211343198"></p><h5 id="搜索文本"><a href="#搜索文本" class="headerlink" title="搜索文本"></a>搜索文本</h5><p>除了简单地阅读文本之外，还有很多方法可以用来查看文本内容。词语索引视图可以显示指定单词地出现情况，同时可以显示一些上下文。</p><p>使用以下方法搜索<code>text1</code>文本中的<code>monstrous</code>单词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text1.concordance(<span class="string">&#x27;monstrous&#x27;</span>)</span><br></pre></td></tr></table></figure><p>搜索结果</p><p><img src="https://ftp.fly97.cn/image/image-20200917212148198.png" alt="image-20200917212148198"></p><p>小试牛刀：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text2.concordance(<span class="string">&#x27;lived&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200917212629370.png" alt="image-20200917212629370"></p><p>关键词索引可以让我们看到上下文中的词，例如，可以看到monstrous出现在文章中，如the __ pictures 和 the __ size，<strong>还有那些词出现在相似地上下文</strong>中？可以通过以下函数查看。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text1.similar(<span class="string">&#x27;monstrous&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200917220851114.png"></p><p>使用以下函数研究<strong>共用两个或者两个以上的词汇的上下文</strong>，如monstrous 和 very. 使用方括号和圆括号讲这些词括起来，中间用逗号分割。</p><p>【在<strong>text2</strong>找到用法、意义与该单词集合相似的词 】</p><p>【用来识别2个关键词相似的词语。】</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text2.common_contexts([&quot;monstrous&quot;, &quot;very&quot;])</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200917223058920.png" alt="image-20200917223058920"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文主要介绍了NLTK语言工具包。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;自然语言处理（NLP）是计算机科学领域与人工智能的一个重要方向。他研究实现人与计算机之间用自然语言进行有效的通信的各种领域和方法，涉及所有用计算机对自然语言处理进行的操作。以下例子是基于Python语言和一个名为NLTK的自然语言工具包的开源库实现的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词：&lt;/strong&gt;自然语言处理，NLP，NLTK&lt;/p&gt;</summary>
    
    
    
    
    <category term="自然语言处理" scheme="https://fly97.cn/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Python的一些高级用法</title>
    <link href="https://fly97.cn/p/Python%E7%9A%84%E4%B8%80%E4%BA%9B%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95.html"/>
    <id>https://fly97.cn/p/Python%E7%9A%84%E4%B8%80%E4%BA%9B%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95.html</id>
    <published>2020-09-10T07:00:00.000Z</published>
    <updated>2020-09-10T07:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>此文介绍了一些Python的一些常见的高级用法。</p><a id="more"></a><h4 id="format格式化字符串"><a href="#format格式化字符串" class="headerlink" title="format格式化字符串"></a>format格式化字符串</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">t = time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, time.localtime())</span><br></pre></td></tr></table></figure><h5 id="按照位置来填充"><a href="#按照位置来填充" class="headerlink" title="按照位置来填充"></a>按照位置来填充</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;现在时刻:&#123;&#125;&quot;</span>.format(t))</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200918213811743.png" alt="image-20200918213811743"></p><h6 id="同一个参数可以填充多次"><a href="#同一个参数可以填充多次" class="headerlink" title="同一个参数可以填充多次"></a>同一个参数可以填充多次</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;现在时刻:&#123;0&#125;---&#123;0&#125;&quot;</span>.format(t))</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200918214059634.png" alt="image-20200918214059634"></p><h5 id="通过索引来填充"><a href="#通过索引来填充" class="headerlink" title="通过索引来填充"></a>通过索引来填充</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">s1 = <span class="string">&quot;hello&quot;</span></span><br><span class="line">l1 = [<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>]</span><br><span class="line">t1 = (<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;&#123;[0]&#125;&quot;</span>.format(s1))</span><br><span class="line">print(<span class="string">&quot;&#123;0[0]&#125;,&#123;0[1]&#125;&quot;</span>.format(l1))</span><br><span class="line">print(<span class="string">&quot;&#123;0[0]&#125;,&#123;0[1]&#125;&quot;</span>.format(t1))</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200918215314962.png" alt="image-20200918215314962"></p><p>另外一种写法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">s1 = <span class="string">&quot;hello&quot;</span></span><br><span class="line">l1 = [<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>]</span><br><span class="line">t1 = (<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;&#123;p[1]&#125;&quot;</span>.format(p=s1))</span><br><span class="line">print(<span class="string">&quot;&#123;p[0]&#125;,&#123;p[1]&#125;&quot;</span>.format(p=l1))</span><br><span class="line">print(<span class="string">&quot;&#123;p[0]&#125;,&#123;p[1]&#125;&quot;</span>.format(p=t1))</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200918215656093.png" alt="image-20200918215656093"></p><h4 id="三元运算符"><a href="#三元运算符" class="headerlink" title="三元运算符"></a>三元运算符</h4><p>固定格式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[on_true]  if  [expression]  else [on_false]</span><br></pre></td></tr></table></figure><p>上式表达的语义为：若<strong>表达式expression</strong>的结果为<strong>真</strong>，该式的结果是**[on_true]<strong>；若</strong>表达式expression<strong>的结果为</strong>假<strong>，则该式的结果是</strong>[on_false]**</p><p>例子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span></span><br><span class="line">b = <span class="number">2</span></span><br><span class="line">c = a-b <span class="keyword">if</span> a&gt;b <span class="keyword">else</span> a+b</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200918221607752.png" alt="image-20200918221607752"></p><h4 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h4><p>Python使用Lambda表达式创建匿名函数</p><ul><li>Lambda只是一个表达式，函数体比def简单的多</li><li>Lambda的主体是一个表达式，而不是一个代码块，只能在lambda表达式中封装有限的逻辑进去</li><li>Lambda函数拥有自己的名字空间，且不能访问自有参数列表之外或全局名字空间里的参数。</li><li>虽然lamda函数看起来只能写一行，却不等于C或C++的内联函数，后者是调用小函数时不占用内存，从而提升运行效率。</li></ul><p>Lambda表达式语法：<code>lambda argument_list: expression</code></p><p>案例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">summary = <span class="keyword">lambda</span> x,y:x+y</span><br><span class="line">print(<span class="string">&quot;summary=&#123;&#125;&quot;</span>.format(summary(<span class="number">3</span>,<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200918230330027.png" alt="image-20200918230330027"></p><p>上述lambda表达式与以下函数等价</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">summary</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x + y</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200918231354891.png" alt="image-20200918231354891"></p><h4 id="map函数"><a href="#map函数" class="headerlink" title="map函数"></a>map函数</h4><p>map是Python的高级函数，为函数式编程提供便利。</p><p>形式为<code>map(func, *iterables)</code>：第一个参数func是一个函数的名字；第二个参数为一个可迭代对象。map将函数func应用于列表的所有元素。</p><p>在Python3之前，map用于返回一个列表，其中结果列表的每个元素都是应用于列表或元组序列相应元素上的func结果。</p><p>在Python3中，map返回一个迭代器。</p><p>实例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">seq_list = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line">F = list(map(<span class="keyword">lambda</span> x:x*x, seq_list))</span><br><span class="line">print(F)</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200918233144997.png" alt="image-20200918233144997"></p><p>map可以用于多个列表，列表不必有相同的长度。map会将<code>lambda函数</code>应用于参数列表的元素，即它首先应用于具有第0个索引的元素，然后应用于具有第一个索引的元素，直到第n个索引。</p><p>如果一个列表的元素少于其他元素，当最短列表消耗完时，map结束迭代。</p><p>示例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">b = [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">c = [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用到多个列表</span></span><br><span class="line">ab = list(map(<span class="keyword">lambda</span> x,y:x + y, a, b))</span><br><span class="line">print(ab)</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200920142041359.png" alt="image-20200920142041359"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 若其中一个列表的元素少于其他元素, 当最短列表消耗完时, map停止迭代</span></span><br><span class="line">ac = list(map(<span class="keyword">lambda</span> x,y:x + y, a, c))</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200920142144318.png" alt="image-20200920142144318"></p><h4 id="Filter函数"><a href="#Filter函数" class="headerlink" title="Filter函数"></a>Filter函数</h4><p>filter也是Python的高级函数，为函数式编程提供便利。其作用是对序列中元素进行筛选，最终获得符合条件的序列。其一般形式为**filter(function, iterable)**，函数提供了一种优雅的方式来过滤掉序列中那个的所有元素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">number = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]</span><br><span class="line"><span class="comment"># 找到序列中的偶数</span></span><br><span class="line">double_number = list(filter(<span class="keyword">lambda</span> x:x % <span class="number">2</span> ==<span class="number">0</span>, number))</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200920144322294.png" alt="image-20200920144322294"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;此文介绍了一些Python的一些常见的高级用法。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Python" scheme="https://fly97.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>记一次重装系统</title>
    <link href="https://fly97.cn/p/%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%87%8D%E8%A3%85Win10%E7%B3%BB%E7%BB%9F.html"/>
    <id>https://fly97.cn/p/%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%87%8D%E8%A3%85Win10%E7%B3%BB%E7%BB%9F.html</id>
    <published>2020-09-03T12:46:00.000Z</published>
    <updated>2020-09-03T12:46:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要介绍了如何使用U盘进行重装系统，主要面向电脑小白用户。</p><p><strong>关键字</strong>：重装win10，电脑重装</p><a id="more"></a><p><strong><font color="red">对重装系统过程有疑问的小伙伴可以点击右下角对话窗口联系我！切勿自己胡乱操作以免造成数据损失！</font></strong></p><p><strong>下载链接有时间和流量限制，不定期开放！若链接过期请自行寻找下载链接！</strong></p><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><ol><li>大于<strong>8G</strong>的U盘</li><li>微PE，<a href="https://ftp.fly97.cn/file/wepe_64.exe">点击此处下载</a></li><li>Windows 10 1909原版系统镜像，<a href="https://ftp.fly97.cn/file/cn_windows_10_business_editions_version_1909_updated_april_2020_x64_dvd_5d3fcf2e.iso">点击此处下载</a></li></ol><h3 id="制作启动盘"><a href="#制作启动盘" class="headerlink" title="制作启动盘"></a>制作启动盘</h3><p>制作系统盘期间需要格式化U盘，如有需要请先备份U盘的文件。</p><h4 id="打开微PE工具箱"><a href="#打开微PE工具箱" class="headerlink" title="打开微PE工具箱"></a>打开微PE工具箱</h4><p>双击打开即可。</p><p><img src="https://ftp.fly97.cn/image/20200826101947.png"></p><h4 id="选择其他安装方式"><a href="#选择其他安装方式" class="headerlink" title="选择其他安装方式"></a>选择其他安装方式</h4><p>注意不要点击<strong>立即安装进系统</strong></p><p><img src="https://ftp.fly97.cn/image/20200826102028.png"></p><h4 id="选择安装PE进U盘"><a href="#选择安装PE进U盘" class="headerlink" title="选择安装PE进U盘"></a>选择安装PE进U盘</h4><p>注意待写入U盘<strong>盘符、容量</strong>是不是正确，安装方法默认即可。</p><p><img src="https://ftp.fly97.cn/image/20200826102211.png"></p><h4 id="等待安装完毕"><a href="#等待安装完毕" class="headerlink" title="等待安装完毕"></a>等待安装完毕</h4><p><img src="https://ftp.fly97.cn/image/20200826102242.png"></p><p>稍后片刻，安装速度视U盘写入速度决定，建议安装过程中<strong>不要操作电脑</strong>。</p><p><img src="https://ftp.fly97.cn/image/20200826102535.png"></p><h4 id="检查启动盘是否制作成功"><a href="#检查启动盘是否制作成功" class="headerlink" title="检查启动盘是否制作成功"></a>检查启动盘是否制作成功</h4><p>安装完毕后，打开<strong>此电脑</strong>，如果发现多了两个盘符，则视为完整成功。</p><p>如果没有发现多余的盘符，重新插拔U盘后再尝试查看。</p><p><img src="https://ftp.fly97.cn/image/20200826102652.png"></p><h4 id="将下载的镜像复制进U盘"><a href="#将下载的镜像复制进U盘" class="headerlink" title="将下载的镜像复制进U盘"></a>将下载的镜像复制进U盘</h4><p>切记切记！复制文件的速度视U盘读写速度决定，请耐心等待。</p><h3 id="切换到Windows-PE"><a href="#切换到Windows-PE" class="headerlink" title="切换到Windows PE"></a>切换到Windows PE</h3><p>将U盘插入电脑并重启电脑，切换到Windows PE系统。</p><p>大多数的电脑都提供了启动选项菜单，开机的时候按住对应的快捷键即可进入启动选择界面。</p><p>重启时，电脑亮屏后立马按下对应的快捷键。</p><p><img src="https://ftp.fly97.cn/image/1281268-20190308133836366-1665479547.jpg"></p><p>如果电脑键盘还有Fn键，且重启过程单独按下<strong>快捷键</strong>无效，那么可以尝试按下<strong>Fn键+快捷键</strong>，反复尝试几次。</p><h4 id="选择U盘启动"><a href="#选择U盘启动" class="headerlink" title="选择U盘启动"></a>选择U盘启动</h4><p>使用键盘的上下进行选择，然后敲回车。这里以<strong>Shinelon</strong>笔记本为例。这款笔记本的启动项选择的快捷键是<strong>F7</strong>.</p><p>不同品牌的笔记本启动项选择的界面可能不同，但都<strong>大同小异</strong>。</p><p>选择<strong>已经写入好PE</strong>的U盘，如下图所示。<img src="https://ftp.fly97.cn/image/photo_2020-08-27_16-18-31.jpg"></p><h4 id="进入PE系统"><a href="#进入PE系统" class="headerlink" title="进入PE系统"></a>进入PE系统</h4><p>如果上述操作没有问题，会出现一个<strong>Windows Boot Mananger</strong>的选择界面，选择第一项即可。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-27_16-18-35.jpg"></p><p>进入PE以后的界面，如下图所示。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_11-06-55.png"></p><h4 id="进行磁盘分区"><a href="#进行磁盘分区" class="headerlink" title="进行磁盘分区"></a>进行磁盘分区</h4><p><strong><em>注意：如果不需要改变磁盘分区的大小，只想格式化原有的系统盘并安装全新的系统，此步可以跳过！直接跳转到下一步安装全新系统！强烈建议小白跳过此步！</em></strong></p><p>打开上图所示的<strong>分区助手</strong>，找到你要安装的磁盘，如下图所示。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_11-07-46.png"></p><p><em>操作到这里要注意：</em></p><ol><li>如果你的电脑只有一个磁盘，继续操作会丢失<strong>全部硬盘</strong>的数据！切记切记！</li><li>如果你的电脑和我一样有多个磁盘，请选中你要安装系统的磁盘。继续操作会丢失<strong>以前系统盘</strong>的数据！</li></ol><p>进行<strong>磁盘分区</strong>是为了便于磁盘管理，和磁盘的个数无关。</p><ol><li>如果你的电脑只有一个磁盘，接下来进行的<strong>快捷分区操作</strong>你可以选择<u>多分出几个分区</u>，重装完毕后打开此电脑，你选了几个分区就会看到有几个盘。</li><li>如果你的电脑和我一样有多个磁盘，建议将要安装系统的磁盘<u>全部分成一个区</u>，这样后期不会因为C盘容量较小而影响系统正常运行。具体参照以下步骤。</li></ol><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_11-09-06.png"></p><p>注意，如果你的电脑有多个磁盘，请不要选错。分区数目视个人情况决定，多磁盘建议<strong>一个分区</strong>。磁盘的类型请选择<strong>GPT</strong>，注意勾选<strong>重建MBR</strong>、<strong>创建ESP和MSR分区</strong>。如果你的系统盘是<strong>固态硬盘</strong>，请<strong>勾选分区对其到4096扇区</strong>。</p><p>一般来说，如果你的电脑有多个磁盘，那么一个是<strong>传统的机械硬盘</strong>，一个是固态硬盘。固态硬盘的读写速度要比机械硬盘的读写速度要快得多。所以一般将固态硬盘安装成系统盘。</p><p>点击开始执行，进行系统分区。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_11-09-48.png"></p><p><strong><em>执行过程中请勿操作电脑！否则有可能对磁盘造成不可逆的损害！等待执行完毕。</em></strong></p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_11-09-53.png"></p><p>执行完毕后的新磁盘，如下图所示：</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_11-10-15.png"></p><p>可以看到，磁盘已经被清空，且只有一个<strong>系统</strong>分区。</p><h4 id="还原系统镜像"><a href="#还原系统镜像" class="headerlink" title="还原系统镜像"></a>还原系统镜像</h4><p>此步是重装系统的核心步骤，主要就是将全新的系统还原到系统盘中。</p><p>打开PE系统桌面的<strong>CGI备份还原</strong>，如图所示：</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_11-11-47.png"></p><p>选择<strong>还原分区</strong>，一般来说，分区会默认选择好。通过<strong>盘符</strong>、<strong>可用空间</strong>和<strong>卷标</strong>来判断是不是系统盘。</p><p>镜像文件选择已经移动到U盘里的ISO文件，并选择<u>Windows 10 Pro</u> 即 <u>Windows10专业版</u> 的镜像。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_11-12-18.png"></p><p>点击执行，选中<strong>不保留目标分区的文件</strong>。最后点击确定。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_11-12-41.png"></p><p><strong><em>等待执行完毕，进度条大概会走三次，执行过程中请勿操作电脑！</em></strong></p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_11-13-24.png"></p><p>执行完毕后，请自行重启。点击<strong>开始</strong> ==&gt; <strong>重启</strong>。电脑黑屏以后可以将U盘拔出，以免下次启动再进入U盘的PE系统。</p><h4 id="进入新系统"><a href="#进入新系统" class="headerlink" title="进入新系统"></a>进入新系统</h4><p>重启过程可能比较慢。请耐心等待。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-39-49.jpg"></p><p>海内存知己，天涯若比邻。无为在歧路，儿女共沾巾。</p><p>出自唐代诗人王勃《送杜少府之任蜀州》</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-43-30.jpg"></p><p>接下来是设置区域。默认帮你选好中国。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-43-32.jpg"></p><p>然后是设置网络。这里推荐设置，连接网络以后Win 10 可以帮你安装<strong>硬件设备的驱动</strong>。<strong>没有硬件驱动的电脑显卡，声卡，以及其他设备可能无法正常工作。</strong>由于个人网络原因这里选择不连接。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-43-35.jpg"></p><p>再次推荐你连接到网络。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-43-43.jpg"></p><p>接受许可协议。不接受无法继续安装23333</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-43-46.jpg"></p><p>设置用户名。这里推荐设置英文的用户名，以免安装一些软件时出现一些莫名其妙的问题。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-43-48.jpg"></p><p>接下来是设置密码。可以留空。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-43-55.jpg"></p><p>选择隐私设置。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-43-58.jpg"></p><p>继续下一步。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-44-01.jpg"></p><p>设置微软个人助理小娜。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-44-09.jpg"></p><p>耐心等待。这是最后一步了。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-45-47.jpg"></p><p>即将完成。</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-45-50.jpg"></p><p>熟悉的Windows 窗口又回来了！</p><p><img src="https://ftp.fly97.cn/image/photo_2020-08-28_09-45-52.jpg"></p><p>至此，系统安装已经完成。后续还有<strong>激活系统，安装office办公软件</strong>等其他操作。</p><h3 id="后续操作"><a href="#后续操作" class="headerlink" title="后续操作"></a>后续操作</h3><h4 id="激活系统"><a href="#激活系统" class="headerlink" title="激活系统"></a>激活系统</h4><p>激活软件：<a href="https://ftp.fly97.cn/file/HWIDGen_CN.exe">点此下载</a></p><p>打开激活软件，需要<strong>连接网络</strong>。点击<strong>数字激活</strong>。稍后片刻提示激活成功。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_12-47-49.png"></p><p>接下来是还原<strong>此电脑，控制面板等一系列图标</strong></p><p>单机<strong>桌面</strong> ==&gt; <strong>个性化</strong>，找到<strong>主题</strong>。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_12-43-21.png"></p><p>下拉菜单，选择桌面光标设置</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_12-44-11.png"></p><p>根据需要找回桌面图标。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_12-44-43.png"></p><p>回到<strong>桌面</strong>，右击<strong>此电脑</strong>，找到<strong>属性</strong>。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_12-46-28.png"></p><p>这里提示，此电脑已激活。此项激活是永久激活。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_12-46-56.png"></p><p>激活系统的步骤到此结束。</p><h4 id="安装office-2019-办公软件"><a href="#安装office-2019-办公软件" class="headerlink" title="安装office 2019 办公软件"></a>安装office 2019 办公软件</h4><h5 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h5><p>下载地址：<a href="https://ftp.fly97.cn/file/proplus2019retail.img">点此下载</a></p><h5 id="安装office"><a href="#安装office" class="headerlink" title="安装office"></a>安装office</h5><p>右键下载好的镜像，选择<strong>装载</strong>。</p><p><img src="https://ftp.fly97.cn/image/image-20200903185027426.png">)</p><p><img src="https://ftp.fly97.cn/image/image-20200903185124252.png"></p><p>打开<strong>此电脑</strong>，此时会发现已经多出来一个<strong>DVD驱动器</strong>，如图所示。</p><p><img src="https://ftp.fly97.cn/image/image-20200903185325374.png" alt="image-20200903185325374"></p><p>双击打开，点击<strong>setup.exe</strong>，开始安装。</p><p><img src="https://ftp.fly97.cn/image/image-20200903185504419.png"></p><p>注意：如果不想安装office的全部组件，只想安装诸如<strong>word、excel、powerpoint</strong>等核心组件，请参考以下步骤：</p><h6 id="下载辅助安装软件"><a href="#下载辅助安装软件" class="headerlink" title="下载辅助安装软件"></a>下载辅助安装软件</h6><p>Office Tool v7.6：<a href="https://ftp.fly97.cn/file/Office-Tool-v7.6.zip">点击下载</a></p><h6 id="双击运行"><a href="#双击运行" class="headerlink" title="双击运行"></a>双击运行</h6><p>该软件无需安装，双击打开即可。</p><p><img src="https://ftp.fly97.cn/image/image-20200903190222874.png"></p><h6 id="开始部署office"><a href="#开始部署office" class="headerlink" title="开始部署office"></a>开始部署office</h6><p>点击部署，进入部署选择菜单</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_20-31-44.png"></p><p>选择<strong>已经挂载好的DVD驱动器</strong>，打开<strong>Office ==&gt; Data</strong>文件夹，选中<strong>v64</strong>，点击打开。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_20-32-45.png"></p><p>架构选择<strong>x64</strong>，安装方式为离线安装，安装模块为office部署工具。根据自身需要安装所需要的office应用程序。这里以<strong>Excel、PowerPoint和Word</strong>为例。最后点击开始部署。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_20-35-09.png"></p><h5 id="等待安装完毕-1"><a href="#等待安装完毕-1" class="headerlink" title="等待安装完毕"></a>等待安装完毕</h5><p>耐心等待即可。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_20-35-28.png"></p><h5 id="安装完毕"><a href="#安装完毕" class="headerlink" title="安装完毕"></a>安装完毕</h5><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_20-37-09.png"></p><h5 id="使用KMS密钥管理服务激活office"><a href="#使用KMS密钥管理服务激活office" class="headerlink" title="使用KMS密钥管理服务激活office"></a>使用KMS密钥管理服务激活office</h5><p>打开上文提到的辅助安装工具，进入激活选择菜单。</p><p>许可证管理选项中，选择<strong>Office 2019 Volume</strong>，点击安装许可证。**<em>出现产品密钥安装成功则已安装完毕。**</em></p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_20-50-20.png"></p><p>KMS管理选项中，输入<strong>windows.kms.app</strong>，检测KMS可用性。</p><p>右侧出现<strong>successful</strong>则说明这个kms服务器是可用的。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_20-50-40.png"></p><p>点击激活，最后出现<strong>产品激活成功</strong>。到此激活完毕。</p><p><img src="https://ftp.fly97.cn/image/Snipaste_2020-08-26_20-51-19.png"></p><p>使用密钥管理服务激活office，每次激活成功以后可以使用180天，180天以后自动重新激活，只要<strong>KMS激活服务器</strong>还在生效就可以一直续期。可以实现<strong>永久激活</strong>。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文主要介绍了如何使用U盘进行重装系统，主要面向电脑小白用户。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键字&lt;/strong&gt;：重装win10，电脑重装&lt;/p&gt;</summary>
    
    
    
    
    <category term="教程" scheme="https://fly97.cn/tags/%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>使用Github Action定时重启IBM cloud foundry</title>
    <link href="https://fly97.cn/p/ibm-cloud-auto-restart.html"/>
    <id>https://fly97.cn/p/ibm-cloud-auto-restart.html</id>
    <published>2020-08-27T10:46:00.000Z</published>
    <updated>2020-08-27T10:46:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文简单介绍了Github Action的用法，并使用Gihub Action定时重启IBM cloud foundry容器。</p><p><strong>摘要：</strong>GitHub Actions是GitHub自家的持续集成及自动化工作流服务，它使用起来非常简单，只要在你的仓库根目录建立<code>.github/workflows</code>文件夹，将你的工作流配置(YML文件)放到这个目录下，就能启用GitHub Actions服务。</p><p><strong>关键字</strong>：Github Action，IBM cloud foundry</p><a id="more"></a><h3 id="yml配置文件"><a href="#yml配置文件" class="headerlink" title="yml配置文件"></a>yml配置文件</h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">IBM</span> <span class="string">Cloud</span> <span class="string">Auto</span> <span class="string">Restart</span></span><br><span class="line"></span><br><span class="line"><span class="attr">on:</span></span><br><span class="line">  <span class="attr">push:</span></span><br><span class="line">    <span class="attr">branches:</span> [ <span class="string">master</span> ]</span><br><span class="line">  <span class="attr">pull_request:</span></span><br><span class="line">    <span class="attr">branches:</span> [ <span class="string">master</span> ]</span><br><span class="line">  <span class="attr">schedule:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">cron:</span> <span class="string">&#x27;0 0 * * *&#x27;</span>      <span class="comment"># 根据自己的需要设置何时重启</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">ibm-cloud-restart:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v2</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Init</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line">        <span class="string">wget</span> <span class="string">-q</span> <span class="string">-O</span> <span class="bullet">-</span> <span class="string">https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key</span> <span class="string">|</span> <span class="string">sudo</span> <span class="string">apt-key</span> <span class="string">add</span> <span class="bullet">-</span></span><br><span class="line">        <span class="string">echo</span> <span class="string">&quot;deb https://packages.cloudfoundry.org/debian stable main&quot;</span> <span class="string">|</span> <span class="string">sudo</span> <span class="string">tee</span> <span class="string">/etc/apt/sources.list.d/cloudfoundry-cli.list</span></span><br><span class="line">        <span class="string">sudo</span> <span class="string">apt-get</span> <span class="string">update</span></span><br><span class="line">        <span class="string">sudo</span> <span class="string">apt-get</span> <span class="string">install</span> <span class="string">cf-cli</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Login</span> <span class="string">IBM</span> <span class="string">Cloud</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="attr">IBM_ACCOUNT:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.IBM_ACCOUNT</span> <span class="string">&#125;&#125;</span></span><br><span class="line">        <span class="attr">IBM_PASSWORD:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.IBM_PASSWORD</span> <span class="string">&#125;&#125;</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line">        <span class="string">cf</span> <span class="string">login</span> <span class="string">-a</span> <span class="string">https://api.us-south.cf.cloud.ibm.com</span> <span class="string">-u</span> <span class="string">$IBM_ACCOUNT</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span></span><br><span class="line">        <span class="string">$IBM_PASSWORD</span></span><br><span class="line">        <span class="string">EOF</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Get</span> <span class="string">IBM</span> <span class="string">Cloud</span> <span class="string">Apps</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line">        <span class="string">cf</span> <span class="string">a</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Restart</span> <span class="string">IBM</span> <span class="string">Cloud</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="attr">IBM_APP_NAME:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.IBM_APP_NAME</span> <span class="string">&#125;&#125;</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line">        <span class="string">cf</span> <span class="string">restart</span> <span class="string">$IBM_APP_NAME</span></span><br></pre></td></tr></table></figure><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><h4 id="fork仓库：https-github-com-wf09-IBMWorkflow"><a href="#fork仓库：https-github-com-wf09-IBMWorkflow" class="headerlink" title="fork仓库：https://github.com/wf09/IBMWorkflow"></a>fork仓库：<a href="https://github.com/wf09/IBMWorkflow">https://github.com/wf09/IBMWorkflow</a></h4><h4 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">IBM_ACCOUNT：账户邮箱</span><br><span class="line"></span><br><span class="line">IBM_APP_NAME：app的名字</span><br><span class="line"></span><br><span class="line">IBM_PASSWORD：密码</span><br></pre></td></tr></table></figure><p>设置完环境变量以后记得commit一下yml文件触发Action。</p><h4 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h4><p><img src="https://ftp.fly97.cn/image/image-20200827193322808.png"></p><p>PS：达拉斯的容器测试通过，其他的地区可能需要将<code>https://api.us-south.cf.cloud.ibm.com</code>修改成你所在的地区。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文简单介绍了Github Action的用法，并使用Gihub Action定时重启IBM cloud foundry容器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;GitHub Actions是GitHub自家的持续集成及自动化工作流服务，它使用起来非常简单，只要在你的仓库根目录建立&lt;code&gt;.github/workflows&lt;/code&gt;文件夹，将你的工作流配置(YML文件)放到这个目录下，就能启用GitHub Actions服务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键字&lt;/strong&gt;：Github Action，IBM cloud foundry&lt;/p&gt;</summary>
    
    
    
    
    <category term="github" scheme="https://fly97.cn/tags/github/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch中的损失函数和优化器</title>
    <link href="https://fly97.cn/p/PyTorch%E4%B8%AD%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8.html"/>
    <id>https://fly97.cn/p/PyTorch%E4%B8%AD%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8.html</id>
    <published>2020-08-20T08:54:00.000Z</published>
    <updated>2020-08-20T08:54:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍了 PyTorch 的损失函数和优化器。</p><p><strong>关键字</strong>：PyTorch，损失函数，优化器</p><a id="more"></a><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>一般来说，PyTorch的损失函数有两种形式：函数形式和模块形式。前者调用的是torch.nn.funtional库中的函数，通过传入神经网络预测值和目标值来计算损失函数，后者是torch.nn库里的模块，通过新建一个模块的实例，然后通过调用模块的方法来计算最终的损失函数。</p><p>由于训练数据一般以<strong>迷你批次</strong>的形式输入神经网络，最后预测的只也是以迷你批次的形式输出的，而损失函数最后的输出结果应该是一个标量张量，因此，对于迷你批次的化简一般有两种方法，一般是对迷你批次的损失函数求和，第二种是对迷你批次的损失函数u求平均。一般来说，也是默认和最常见的情形，最后输出的损失函数是迷你批次损失函数的平均。</p><p>神经网络处理的预测问题主要分为<strong>回归问题和分类问题</strong>。对于回归问题，一般情况下使用的是<code>torch.nn.MSELoss</code>模块，即平方损失函数。通过创建这个模块的实例（一般使用默认参数，即在类的构造函数中不传入任何参数，这样会输出迷你批次的平均；如果要输出迷你批次的每个损失函数，可以指定参数<code>reduction=&#39;none&#39;</code>；如果要输出迷你批次的损失函数，可以指定参数<code>reduction=&#39;sum&#39;</code>.在实例中传入神经网络预测的值和目标值，能够计算得到最终的损失函数。具体的代码可以参考：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">mse = t.nn.MSELoss()  <span class="comment">#初始化平方损失模块</span></span><br><span class="line">t1 = t.randn(<span class="number">5</span>, requires_grad=<span class="literal">True</span>) <span class="comment"># 随机生成张量t1</span></span><br><span class="line">t2 = t.randn(<span class="number">5</span>, requires_grad=<span class="literal">True</span>) <span class="comment"># 随机生成张量t2</span></span><br><span class="line">mse(t1, t2) <span class="comment"># 计算张量t1和t2之间的平方损失函数</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor(0.9193, grad_fn=&lt;MeanBackward0&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">bse = t.nn.BCELoss() <span class="comment"># 初始化二分类交叉损失函数</span></span><br><span class="line">t1 = t.randn(<span class="number">5</span>, requires_grad=<span class="literal">True</span>) <span class="comment">#随机生成张量t1</span></span><br><span class="line">t1s = t.sigmoid(t1) <span class="comment"># 对张量求sigmoid函数, 转换为(0, 1)之间的概率</span></span><br><span class="line">t2 = t.randint(<span class="number">0</span>, <span class="number">2</span>, (<span class="number">5</span>,)).float() <span class="comment">#随机生成0, 1整数序列, 并转换为浮点数</span></span><br><span class="line">bse(t1s, t2) <span class="comment">#计算二分类的交叉熵</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor(0.8674, grad_fn=&lt;BinaryCrossEntropyBackward&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">bce_logits = t.nn.BCEWithLogitsLoss() <span class="comment">#初始化交叉熵对数损失函数</span></span><br><span class="line">bce_logits(t1, t2) <span class="comment">#计算二分类的交叉熵 (和前面结果一样)</span></span><br><span class="line"><span class="comment"># 这是因为, BCEWithLogitsLoss会先让输入经过sigmoid函数, 变成概率分布的形式, 再计算二分类交叉熵.</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor(0.8674, grad_fn=&lt;BinaryCrossEntropyWithLogitsBackward&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">N = <span class="number">10</span> <span class="comment"># 定义分类数目</span></span><br><span class="line">t1 = t.randn(<span class="number">5</span>, N, requires_grad=<span class="literal">True</span>) <span class="comment">#随机产生预测张量</span></span><br><span class="line">t2 = t.randint(<span class="number">0</span>, N, (<span class="number">5</span>, ))            <span class="comment">#随机产生目标张量</span></span><br><span class="line">t1s = t.nn.functional.log_softmax(t1, <span class="number">-1</span>) <span class="comment"># 计算预测张量的LogSoftmax</span></span><br><span class="line">nll = t.nn.NLLLoss() <span class="comment">#定义NLL损失函数</span></span><br><span class="line">nll(t1s, t2) <span class="comment">#计算损失函数</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor(2.3238, grad_fn=&lt;NllLossBackward&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">ce = t.nn.CrossEntropyLoss() <span class="comment">#定义交叉熵损失函数</span></span><br><span class="line">ce(t1, t2) <span class="comment"># 和前面计算结果相同</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor(2.3238, grad_fn=&lt;NllLossBackward&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span> </span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文介绍了 PyTorch 的损失函数和优化器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键字&lt;/strong&gt;：PyTorch，损失函数，优化器&lt;/p&gt;</summary>
    
    
    
    
    <category term="PyTorch" scheme="https://fly97.cn/tags/PyTorch/"/>
    
    <category term="计算图" scheme="https://fly97.cn/tags/%E8%AE%A1%E7%AE%97%E5%9B%BE/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch中的自动求导机制和计算图</title>
    <link href="https://fly97.cn/p/PyTorch%E4%B8%AD%E7%9A%84%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E6%9C%BA%E5%88%B6%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE.html"/>
    <id>https://fly97.cn/p/PyTorch%E4%B8%AD%E7%9A%84%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E6%9C%BA%E5%88%B6%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE.html</id>
    <published>2020-08-18T05:27:00.000Z</published>
    <updated>2020-08-18T05:27:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍了 PyTorch 的自动求导机制和计算图。</p><p><strong>摘要</strong>：深度学习的算法本质是通过反向传播求导数，PyTorch 的 <code>Autograd</code>模块实现了此功能。在 Tensor 上的所有操作，<code>Autograd</code>都能为他们自动提供微分，避免手动求导的复杂过程。</p><p><strong>关键字</strong>：PyTorch，自动求导，计算图</p><a id="more"></a><p>PyTorch会根据计算过程来自动生成动态图，然后根据动态图的创建过程进行反向传播，计算得到每个节点的梯度值。为了能够记录张量的梯度，首先需要在创建张量的时候设置一个参数<code>requires_grad=True</code>，意味着这个张量将会加入到计算图中，作为计算图的叶子节点参与计算通过一系列的计算最后输出结果张量，也就是根节点。几乎所有的张量创建方式都可以指定这个参数，一旦指定了这个参数，在后续的计算中得到的中间结果的张量都会被设置成<code>requires_grad=True</code>。对于PyTorch 来说，每一个张量都有一个<code>grad_fn</code>方法，这个方法包含创建该张量的运算的导数信息。在反向传播过程中，通过传入后一层的神经网络的梯度，该函数会计算出参与运算的所有张量的梯度，<code>grad_fn</code>本身也携带着计算图的信息，该方法本身有一个<code>next_functions</code>属性，包含连接该张量的其他张量的<code>grad_fn</code>。通过不断反向传播回溯中间张量的计算节点，可以得到所有张量的梯度。一个张量的梯度张量的信息保存在该张量的grad属性中。</p><p>除 PyTorch 张量本身外，PyTorch提供了一个专门用来自动求导的包，即<code>torch.autograd</code>.它包含了两个重要的函数，即<code>torch.autograd.backward</code>函数和<code>torch.autograd.grad</code>函数。</p><p><code>torch.autograd.backward</code>函数通过传入根节点张量，以及起始梯度张量(形状和当前张量的相同)，可以计算产生该根节点所有对应的叶子节点的梯度。当张量为标量张量(即只有一个元素的张量)时，可以不传入起始梯度张量，默认会设置初始梯度张量为1。当计算梯度张量时，原来建立起来的计算图会自动被释放，如果需要再次做自动求导，因为计算图会被自动释放，如果需要再次做自动求导，因为计算图已经不存在，就会报错。如果要在反向传播的时候保留计算图，可以设置<code>retain_graph=True</code>。另外，在自动求导的时候默认不会建立反向传播的计算图(反向传播也是一个计算过程，可以动态创建计算图)，如果需要在反向传播计算的同时建立和梯度张量有关的计算图(在某些情况下，如需要计算高阶导数的情况下，不过这种情况比较少)，可以设置<code>creat_graph=True</code>。对于一个可求导的张量，也可以直接调用该张量内部的<code>backward</code>方法来进行自动求导。</p><h2 id="自动求导机制实例"><a href="#自动求导机制实例" class="headerlink" title="自动求导机制实例"></a>自动求导机制实例</h2><p>下面举一个简单的例子来说明自动求导是如何使用的。根据高等数学的知识可知，若定义一个函数$f(x)=x^2$，则它的导数$f(x)=2x$。于是可以创建一个可求导的张量来测试具体的导数。具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> t</span><br><span class="line"></span><br><span class="line">t1 = t.randn(<span class="number">3</span>, <span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">t1</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[-0.6704,  1.1710,  0.7608],</span></span><br><span class="line"><span class="string">        [ 1.2378, -0.5393, -0.9865],</span></span><br><span class="line"><span class="string">        [ 0.2863,  0.5295, -0.4555]], requires_grad=True)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">t2 = t1.pow(<span class="number">2</span>).sum() </span><br><span class="line">t2.backward(retain_graph=<span class="literal">True</span>) <span class="comment">#梯度反向传播</span></span><br><span class="line">t1.grad <span class="comment">#梯度是张量原始分量的2倍</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;tensor([[-1.3407,  2.3419,  1.5216],</span></span><br><span class="line"><span class="string">        [ 2.4756, -1.0786, -1.9729],</span></span><br><span class="line"><span class="string">        [ 0.5725,  1.0589, -0.9110]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">t2 = t1.pow(<span class="number">2</span>).sum()  <span class="comment">#再次计算张量的所有分量平方和</span></span><br><span class="line">t2.backward() <span class="comment"># 梯度再次反向传播</span></span><br><span class="line">t1.grad <span class="comment">#梯度累积</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[-2.1156, -1.1415,  7.4562],</span></span><br><span class="line"><span class="string">        [ 0.0900, -4.8776, -0.5413],</span></span><br><span class="line"><span class="string">        [-8.0727, -0.1184, -6.8779]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">t1.grad.zero_() <span class="comment">#梯度清零</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>需要注意的一点是，张量绑定的梯度张量在不清空的情况下会逐渐累积。这种特性在某些情况下是有用的，比如，需要一次性求很多迷你批次的累计梯度，但在一般情况下，不需要用到这个特性，所以要注意将张量的梯度清零。</p><h2 id="梯度函数的使用"><a href="#梯度函数的使用" class="headerlink" title="梯度函数的使用"></a>梯度函数的使用</h2><p>在某些情况下，不需要求出当前张量对所有产生该张量的叶子节点的梯度，此时可以用<code>torch.autograd.grad</code>函数，这个函数的参数是两个张量，第一个张量是计算图的数据结果张量(或是张量列表)，第二个张量是需要对计算图求导的张量(或张量列表)。最后输出的结果是第一个张量对第二个张量求导的结果(注意梯度会累积，和前面介绍的<code>torch.autograd.backward</code>函数的行为一样)。<strong>需要注意的是</strong>，这个函数不会改变叶子节点的grad属性。而函数<code>torch.autograd.backward</code>会设置叶子节点的grad属性为最后求出梯度张量。<code>torch.autograd.grad</code>会在反向传播求导时释放计算图，如果需要保留计算图，同样可以设置<code>retain_graph=True</code>.如果需要反向传播的计算图，可以设置<code>create_graph=True</code>.</p><p>另外，有时候会碰到一种情况是求导的两个张量之间在计算图上没有关联，在这种情况下函数会报错，如果不需要函数的报错行为，可以设置allow_unused=True这个参数，结果会返回分量全为0的梯度张量(因为两个张量没有关联，所以求导的梯度为0).</p><p>具体的使用方法可以参考以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">t1 = t.randn(<span class="number">3</span>, <span class="number">3</span>, requires_grad=<span class="literal">True</span>) <span class="comment">#初始化t1张量</span></span><br><span class="line">t1</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[-0.1082, -1.0099, -0.4560],</span></span><br><span class="line"><span class="string">        [-0.3910, -0.9767,  0.6419],</span></span><br><span class="line"><span class="string">        [ 1.1544,  0.3572, -1.3304]], requires_grad=True)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">t2 = t1.pow(<span class="number">2</span>).sum() <span class="comment">#根据t1张量求t2张量</span></span><br><span class="line">t.autograd.grad(t2, t1) <span class="comment"># t2张量对t1张量求导</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(tensor([[-0.2165, -2.0197, -0.9120],</span></span><br><span class="line"><span class="string">         [-0.7820, -1.9535,  1.2837],</span></span><br><span class="line"><span class="string">         [ 2.3088,  0.7145, -2.6608]]),)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h2 id="计算图的构建的启用和禁用"><a href="#计算图的构建的启用和禁用" class="headerlink" title="计算图的构建的启用和禁用"></a>计算图的构建的启用和禁用</h2><p>由于计算图的构建需要消耗内存和计算资源，在一些情况下，计算图并不是必要的，比如<strong>神经网络的推导</strong>。在这种情况下，可以使用<code>torch.no_grad</code>上下文管理器，在这个上下文管理器的作用域内进行的神经网络计算不会构建任何计算图。</p><p>另外，还有一种情况是对于一个张量，我们在反向传播的时候可能不需要让梯度通过这个张量的节点，也就是新建的计算图要和原来的计算图分离。在这种情况下，可以使用张量的<code>detach</code>方法，通过调用这个方法，可以返回一个新的张量，该张量会成为一个新的计算图的叶子节点，新的计算图和老的计算图互相分离，互不影响。具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">t1 = t.randn(<span class="number">3</span>, <span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">t2 = t1.sum()</span><br><span class="line"></span><br><span class="line">t2   <span class="comment">#t2的计算构建了计算图，输出结果带有grad_fn</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> tensor(2.2761, grad_fn=&lt;SumBackward0&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> t.no_grad():</span><br><span class="line">    t3 = t1.sum()</span><br><span class="line">    </span><br><span class="line">t3  <span class="comment">#t3的计算没有构建计算图，输出结果没有grad_fn</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor(2.2761)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">t1.sum()   <span class="comment">#保持原来的计算图</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor(2.2761, grad_fn=&lt;SumBackward0&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">t1.sum().detach()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> tensor(2.2761)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><p>如果我们需要计算某个Tensor的导数，那么我们需要设置其<code>requires_grad=True</code>.</p><p>Tensor包含以下属性：</p><ul><li><code>grad</code>：保存tensor的梯度，形状与Tensor一致。每次在计算backward时都需要将前一时刻的梯度归零，否则梯度值会一直累加。</li><li><code>grad_fn</code>：指向一个Function，记录Tensor的操作历史，即它是什么操作的输出，用来构建计算图。如果某一个变量是由用户创建的，则他为<strong>叶子节点</strong>，对应的<code>grad_fn</code>等于<code>None</code>。只有<strong>根节点</strong>的<code>grad_fn</code>才有效，用于指示梯度函数是哪种类型。</li><li><code>is_leaf</code>: 用来指示该Tensor是否是叶子节点。</li><li><code>requires_grad</code>: 设置为<code>True</code>则表示该Tensor需要求导</li></ul><p>通过几个例子来了解一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> t</span><br><span class="line"></span><br><span class="line">a = t.ones(<span class="number">3</span>, <span class="number">4</span>, requires_grad = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">a</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1., 1., 1.]], requires_grad=True)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">b = t.zeros(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">b</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[0., 0., 0., 0.],</span></span><br><span class="line"><span class="string">        [0., 0., 0., 0.],</span></span><br><span class="line"><span class="string">        [0., 0., 0., 0.]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 张量加法</span></span><br><span class="line"></span><br><span class="line">c = a + b</span><br><span class="line">c</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1., 1., 1.]], grad_fn=&lt;AddBackward0&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line">c = a.add(b)</span><br><span class="line">c</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1., 1., 1.]], grad_fn=&lt;AddBackward0&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">d = c.sum()</span><br><span class="line">d.backward() <span class="comment"># 反向传播</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意两者的区别</span></span><br><span class="line">c.data.sum(), c.sum()</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(tensor(12.), tensor(12., grad_fn=&lt;SumBackward0&gt;))</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">a.grad</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1., 1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1., 1., 1.]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 此处虽然没有指定c需要求导，但c依赖于a，a需要求导</span></span><br><span class="line"><span class="comment"># 因此c的requires_grad属性会自动设为True</span></span><br><span class="line">a.requires_grad, b.requires_grad, c.requires_grad</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;(True, False, True)&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 由用户创建的 tensor 属于叶子节点，对应的grad_fn是None</span></span><br><span class="line">a.is_leaf, b.is_leaf, c.is_leaf</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;(True, True, False)&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># c.grad是None, c不是叶子节点, 他的梯度是用来计算a的梯度</span></span><br><span class="line"><span class="comment"># 虽然c.requires_grad = True, 但其梯度计算完了即被释放</span></span><br><span class="line"></span><br><span class="line">c.grad <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;True&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="torch-autograd-backward"><a href="#torch-autograd-backward" class="headerlink" title="torch.autograd.backward"></a>torch.autograd.backward</h3><p>先看一下backward的接口是如何定义的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.autograd.backward(</span><br><span class="line">tensors, </span><br><span class="line">grad_tensors&#x3D;None, </span><br><span class="line">retain_graph&#x3D;None, </span><br><span class="line">create_graph&#x3D;False, </span><br><span class="line">grad_variables&#x3D;None)</span><br></pre></td></tr></table></figure><ul><li><code>tensor</code>: 用于计算梯度的tensor。也就是说这两种方式是等价的：<code>torch.autograd.backward(z) == z.backward()</code></li><li><code>grad_tensors</code>: 在计算矩阵的梯度时会用到。他其实也是一个tensor，shape一般需要和前面的<code>tensor</code>保持一致。</li><li><code>retain_graph</code>: 通常在调用一次backward后，PyTorch会自动把计算图销毁，所以要想对某个变量重复调用backward，则需要将该参数设置为<code>True</code></li><li><code>create_graph</code>: 当设置为<code>True</code>的时候可以用来计算更高阶的梯度</li><li><code>grad_variables</code>: 这个官方说法是grad_variables’ is deprecated. Use ‘grad_tensors’ instead.也就是说这个参数后面版本中应该会丢弃，直接使用<code>grad_tensors</code>.</li></ul><p>使用以下代码尝试解释<code>grad_tensors</code>的作用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = torch.ones(<span class="number">2</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">z = x + <span class="number">2</span></span><br><span class="line">z.backward()</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">RuntimeError: grad can be implicitly created only for scalar outputs</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>当代码被运行，会有一个上述的<code>RuntimeError</code>被抛出。上面的报错信息意思是<strong>只有对标量输出它才会计算梯度</strong>，而求一个矩阵对令一个矩阵的导数束手无策。<br>$$<br>X=[x_0\quad x_1]\quad  Z=X+2=[x_0+2\quad x_1+2]\Rightarrow \frac{\partial Z}{\partial X}=?<br>$$<br>那么我们只要相办法把矩阵转变成一个标量不就好了？比如我们可以对<code>Z</code>求和，然后用求和得到的标量在对x求导，这样不会对结果有影响。即：<br>$$<br>Z_{sum}=\sum{z_i}=x_0+x_1+8\quad then \quad\frac{\partial Z_{sum}}{\partial X_0}=\frac{\partial Z_{sum}}{\partial X_1}=1<br>$$<br>我们可以看到对z求和以后再计算梯度没有报错，结果也和预期一样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> t</span><br><span class="line"></span><br><span class="line">x = t.ones(<span class="number">2</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">z = x + <span class="number">2</span></span><br><span class="line"></span><br><span class="line">z.sum().backward()</span><br><span class="line">x.grad</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([1., 1.])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>我们再仔细想想，对z求和不就是等价于z<strong>点乘一个一样维度的全为1的矩阵</strong>吗？即$sum(Z)=dot(Z,I)$,而这个I也就是我们需要传入的<code>grad_tensor</code>参数。点乘只是对一维向量而言的，对于矩阵或更高维的张量，可以看作是<strong>对每一个维度做点乘</strong>。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> t</span><br><span class="line">x = t.ones(<span class="number">2</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">z = x + <span class="number">2</span></span><br><span class="line"></span><br><span class="line">z.backward(t.ones_like(z))</span><br><span class="line">x.grad</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([1., 1.])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>弄个再复杂一点的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">x = t.tensor([[<span class="number">2.</span>, <span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = t.tensor([[<span class="number">1.</span>, <span class="number">2.</span>], [<span class="number">3.</span>, <span class="number">4.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">z = t.mm(x, y)</span><br><span class="line">print(<span class="string">f&quot;z:<span class="subst">&#123;z&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">z.backward(t.tensor([[<span class="number">1.</span>, <span class="number">0</span>]]), retain_graph=<span class="literal">True</span>)</span><br><span class="line">print(<span class="string">f&quot;x.grad:<span class="subst">&#123;x.grad&#125;</span>&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;y.grad:<span class="subst">&#123;y.grad&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">z:tensor([[5., 8.]], grad_fn=&lt;MmBackward&gt;)</span></span><br><span class="line"><span class="string">x.grad:tensor([[1., 3.]])</span></span><br><span class="line"><span class="string">y.grad:tensor([[2., 0.],</span></span><br><span class="line"><span class="string">        [1., 0.]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>总结：说了这么多，grad_tensors的作用其实可以简单地理解成在求梯度时候地权重，因为可能梯度对影响结果程度不同。</p><p><strong>知乎高赞评论：</strong>假设是在z点backward，输入<code>grad_tensors</code>应该是目标函数(scalar)f对z的梯度，那么<br>$$<br>\frac{\partial f}{\partial X}=\frac{\partial f}{\partial z} \times \frac{\partial z}{\partial x}<br>$$<br>其中，传入的第一项就是传入<code>grad_tensors</code></p><h3 id="导数运算"><a href="#导数运算" class="headerlink" title="导数运算"></a>导数运算</h3><p>接着我们来看看autograd计算的导数和我们手动推导的导数的区别。</p><p>给出下列函数表达式：<br>$$<br>y=x^2e^x<br>$$<br>他的导函数是：<br>$$<br>\frac{\partial y}{\partial x}=2xe^x+x^2e^x<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> t</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算y&quot;&quot;&quot;</span></span><br><span class="line">    y = x**<span class="number">2</span> * t.exp(x)</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradf</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;手动求导函数&quot;&quot;&quot;</span></span><br><span class="line">    dx = <span class="number">2</span>*x*t.exp(x) + x**<span class="number">2</span>*t.exp(x)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机数种子, 使结果可以复现</span></span><br><span class="line">t.manual_seed(<span class="number">0</span>)</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">x = t.randn(<span class="number">3</span>, <span class="number">4</span>, requires_grad = <span class="literal">True</span>)</span><br><span class="line">y = f(x)</span><br><span class="line">y</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[11.0879,  0.0642,  0.5373,  0.5705],</span></span><br><span class="line"><span class="string">        [ 0.3976,  0.4830,  0.2435,  1.6235],</span></span><br><span class="line"><span class="string">        [ 0.2520,  0.1087,  0.1960,  0.0398]], grad_fn=&lt;MulBackward0&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">y.backward(t.ones(y.size())) <span class="comment"># 和grad_tensor形状一致</span></span><br><span class="line">x.grad</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[25.4785, -0.3734,  0.0441,  2.5776],</span></span><br><span class="line"><span class="string">        [-0.3356, -0.2077,  1.4510,  5.4982],</span></span><br><span class="line"><span class="string">        [-0.4487, -0.4302, -0.4611,  0.4765]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y.sum().backward()</span><br><span class="line">x.grad</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[25.4785, -0.3734,  0.0441,  2.5776],</span></span><br><span class="line"><span class="string">        [-0.3356, -0.2077,  1.4510,  5.4982],</span></span><br><span class="line"><span class="string">        [-0.4487, -0.4302, -0.4611,  0.4765]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># autograd的计算结果与利用公式手动计算的结果一致</span></span><br><span class="line">gradf(x)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[25.4785, -0.3734,  0.0441,  2.5776],</span></span><br><span class="line"><span class="string">        [-0.3356, -0.2077,  1.4510,  5.4982],</span></span><br><span class="line"><span class="string">        [-0.4487, -0.4302, -0.4611,  0.4765]], grad_fn=&lt;AddBackward0&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h3><p>PyTorch 中的 autograd 的底层采用了计算图，计算图是一种<strong>特殊的有向无环图(DAG)</strong>.用于记录算子和变量之间的关系。一般用矩形表示算子，椭圆形表示变量。如表达式$z=wx+b$可以分解为$y=wx$和$z=y+b$，其计算图如下图所示，图中的<code>MUL</code>和<code>ADD</code>都是算子，$w、x、b$为变量。</p><img src="https://ftp.fly97.cn/image/image-20200820171041627.png" alt="image-20200820171041627" style="zoom:50%;" /><p>如上有向无环图中，$X$和$b$是叶子节点(leaf node)，这些节点通常由用户自己创建，不依赖其他变量。$z$称为根节点，是计算图的最终目标。利用链式法则很容易求得各个叶子节点的梯度。<br>$$<br>\frac{\partial z}{\partial b}=1\quad\frac{\partial z}{\partial y}=1<br>$$</p><p>$$<br>\frac{\partial y}{\partial w}=x\quad\frac{\partial y}{\partial x}=w<br>$$</p><p>$$<br>\frac{\partial z}{\partial x}=\frac{\partial z}{\partial y} \times\frac{\partial y}{\partial x}=1\times w<br>$$</p><p>$$<br>\frac{\partial z}{\partial w}=\frac{\partial z}{\partial y} \times\frac{\partial y}{\partial w}=1\times x<br>$$</p><p>而有了计算图，上述链式求导即可利用计算图的反向传播自动完成，其传播过程如下图所示。</p><img src="https://ftp.fly97.cn/image/image-20200820172727826.png" alt="image-20200820172727826" style="zoom:50%;" /><p>在 PyTorch 实现中，<code>autograd</code>会随着用户的操作，记录生成当前 <strong>Tensor</strong> 的所有操作，并由此建立一个有向无环图。用户没进行一个操作，相应的计算图就会发生改变。更底层的实现中，图中记录了操作<code>Function</code>，每个变量在图中的位置可通过其<code>grad_fn</code>属性在图中的位置可以推测得到。在反向传播过程中，<code>autograd</code>沿着这个图从当前变量(根节点$z$)溯源，可以利用链式求导法则计算所有叶子节点的梯度。每一个前向传播操作的函数都有与之对应的反向传播函数用来计算输入的各个Tensor的梯度，这些函数的函数名通常以<code>Backward</code>结尾。</p><p>部分转载自：<a href="https://zhuanlan.zhihu.com/p/83172023">https://zhuanlan.zhihu.com/p/83172023</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文介绍了 PyTorch 的自动求导机制和计算图。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;：深度学习的算法本质是通过反向传播求导数，PyTorch 的 &lt;code&gt;Autograd&lt;/code&gt;模块实现了此功能。在 Tensor 上的所有操作，&lt;code&gt;Autograd&lt;/code&gt;都能为他们自动提供微分，避免手动求导的复杂过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键字&lt;/strong&gt;：PyTorch，自动求导，计算图&lt;/p&gt;</summary>
    
    
    
    
    <category term="PyTorch" scheme="https://fly97.cn/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch中的Tensor</title>
    <link href="https://fly97.cn/p/PyTorch%E4%B8%AD%E7%9A%84Tensor.html"/>
    <id>https://fly97.cn/p/PyTorch%E4%B8%AD%E7%9A%84Tensor.html</id>
    <published>2020-08-17T05:27:00.000Z</published>
    <updated>2020-08-17T05:27:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>通过以下几个例子来了解以下PyTorch中的Tensor。</p><a id="more"></a><p>Tensor 是 PyTorch 中重要的数据结构，可认为是一个高维数组。它可以是一个数字（标量）、一维数组（向量）、二维数组（矩阵）或更高维的数组。Tensor 和 numpy 的中的 ndrrays 类似，但是 Tensor 可以使用GPU加速。Tensor 的使用和 numpy 以及MATLAB的接口十分类似。下面通过几个实例来了解一下Tensor的基本使用方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensor <span class="keyword">as</span> t</span><br><span class="line"><span class="comment"># 构建 5*3 矩阵，只是分配了空间，未初始化</span></span><br><span class="line">x = t.Tensor(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用[0, 1]均匀分布随机初始化二维数组</span></span><br><span class="line">x = t.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(x.size()) <span class="comment">#查看形状</span></span><br><span class="line">x.size()[<span class="number">0</span>], x.size(<span class="number">1</span>) <span class="comment">#查看列的个数，两种写法等价</span></span><br><span class="line"></span><br><span class="line">print(t.Size([<span class="number">5</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="comment"># (5L, 3)</span></span><br></pre></td></tr></table></figure><p>touch.Size 是tuple对象的子类，因此它支持 tuple 的所有操作，如 x.size()[0]。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">y = t.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 加法</span></span><br><span class="line">print(x + y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加法2</span></span><br><span class="line">t.add(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加法3</span></span><br><span class="line">result  = t.Tensor(<span class="number">5</span>, <span class="number">3</span>) <span class="comment"># 预先分配空间 </span></span><br><span class="line">t.add(x, y, out=result)  <span class="comment"># 输入到result</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;最初y&#x27;</span>)</span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;第一种加法, y的结果&#x27;</span>)</span><br><span class="line">y.add(x) <span class="comment"># 普通加法, 不改变y的内容</span></span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;第二种加法, y的结果&#x27;</span>)</span><br><span class="line">y.add_(x) <span class="comment"># inplace加法, 执行完后y的值被更新</span></span><br></pre></td></tr></table></figure><p><strong>注意：</strong>函数名后面带下划线的函数会修改 Tensor 本身。例如，<code>x.add(y)</code> 和 <code>x.t_()</code>会返回一个新的 Tensor，而<code>x</code>不变。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tensor的选取操作与numpy类似</span></span><br><span class="line">x[:, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>Tensor 还支持很多操作，包括<strong>数学运算、线性代数、选择、切片</strong>等，其接口涉及与 numpy 极为相似。</p><p>Tensor 和 numpy 的数组间的互操作非常容易且快速。Tensor不支持的操作，可以先转为 numpy 数组处理，之后再转回 Tensor .</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = t.ones(<span class="number">5</span>) <span class="comment"># 新建一个全是1的Tensor</span></span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">b = a.numpy() <span class="comment"># Tensor -&gt; Numpy</span></span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.ones(<span class="number">5</span>)</span><br><span class="line">b = t.from_numpy(a) <span class="comment"># Numpy -&gt; Tensor</span></span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><p>Tensor 和 Numpy 对象<strong>共享内存</strong>，所以他们之间的转换会很快，而且几乎不会消耗资源。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b.add_(<span class="number">1</span>) <span class="comment"># 以_结尾的函数会修改自身</span></span><br><span class="line">print(a) </span><br><span class="line">print(b) <span class="comment"># Tensor和Numpy共享内存</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Tensor可通过<code>.cuda</code>方法转换为GPU的Tensor，从而享受GPU带来的加速运算.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在不支持CUDA的机器下，下一步不会运行</span></span><br><span class="line"><span class="keyword">if</span> t.cuda.is_available():</span><br><span class="line">x = x.cuda()</span><br><span class="line">y = y.cuda()</span><br><span class="line">x + y</span><br></pre></td></tr></table></figure><p>此处可能会发现GPU的运算速度并未提升太多，这是因为 x 和y 太小且运算也比较简单，而且将数据从内存种转移到显存上还需要花费额外的开销。GPU的优势需要在大规模数据和复杂运算上才能体现出来。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;通过以下几个例子来了解以下PyTorch中的Tensor。&lt;/p&gt;</summary>
    
    
    
    
    <category term="PyTorch" scheme="https://fly97.cn/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Python时间处理</title>
    <link href="https://fly97.cn/p/Python%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86.html"/>
    <id>https://fly97.cn/p/Python%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86.html</id>
    <published>2020-08-13T12:31:00.000Z</published>
    <updated>2020-08-13T12:31:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要介绍了Python时间处理的函数。</p><p><strong>摘要</strong>：有时需要在国外的服务器上处理北京时间等非本地时区的时间，经过查找，发现了<code>pytz</code>这个处理时区的包。<code>pytz</code>允许使用Python 2.4或更高版本进行准确的跨平台时区计算。</p><p><strong>关键词</strong>：时区计算，pytz</p><a id="more"></a><h4 id="获得北京时间"><a href="#获得北京时间" class="headerlink" title="获得北京时间"></a>获得北京时间</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time </span><br><span class="line"><span class="keyword">import</span> pytz</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> pytz <span class="keyword">import</span> timezone</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">utc = pytz.utc</span><br><span class="line">utc_dt = utc.localize(datetime.utcfromtimestamp(time.time())) <span class="comment"># 获得UTC时间</span></span><br><span class="line"></span><br><span class="line">shanghai = timezone(<span class="string">&#x27;Asia/Shanghai&#x27;</span>) <span class="comment"># 定义一个时区</span></span><br><span class="line">shanghai_dt = utc_dt.astimezone(shanghai)                     <span class="comment"># 将本地时区的时间转换成UTC时间</span></span><br><span class="line"></span><br><span class="line">fmt = <span class="string">&#x27;%Y-%m-%d %H:%M:%S %Z%z&#x27;</span>                                <span class="comment"># 定义打印时间</span></span><br><span class="line">print(shanghai_dt.strftime(fmt)                               <span class="comment"># 输出指定时区的时间</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>通过Python自带的包也可以方便的进行时区转换。这里使用的是datetime. </p><p>datetime 是Python处理日期和时间的标准库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime, timedelta, timezone</span><br><span class="line"><span class="comment"># 拿到UTC时间，并强制设置时区为UTC+0:00:</span></span><br><span class="line">utc_dt = datetime.utcnow().replace(tzinfo=timezone.utc) </span><br><span class="line">print(utc_dt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># astimezone()将转换时区为北京时间:</span></span><br><span class="line">bj_dt = utc_dt.astimezone(timezone(timedelta(hours=<span class="number">8</span>)))</span><br><span class="line"> <span class="comment"># 定义打印时间的格式</span></span><br><span class="line">fmt = <span class="string">&#x27;%Y-%m-%d %H:%M:%S %Z%z&#x27;</span>   </span><br><span class="line">bj_dt.strftime(fmt)</span><br><span class="line">print(bj_dt)</span><br></pre></td></tr></table></figure><h4 id="打印当地时间"><a href="#打印当地时间" class="headerlink" title="打印当地时间"></a>打印当地时间</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, time.localtime()))</span><br></pre></td></tr></table></figure><p>详细内容可以参考廖老师的这一篇文章</p><p><a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1017648783851616">https://www.liaoxuefeng.com/wiki/1016959663602400/1017648783851616</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文主要介绍了Python时间处理的函数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;：有时需要在国外的服务器上处理北京时间等非本地时区的时间，经过查找，发现了&lt;code&gt;pytz&lt;/code&gt;这个处理时区的包。&lt;code&gt;pytz&lt;/code&gt;允许使用Python 2.4或更高版本进行准确的跨平台时区计算。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词&lt;/strong&gt;：时区计算，pytz&lt;/p&gt;</summary>
    
    
    
    
    <category term="Python" scheme="https://fly97.cn/tags/Python/"/>
    
    <category term="time" scheme="https://fly97.cn/tags/time/"/>
    
  </entry>
  
  <entry>
    <title>nginx.conf配置文件详解</title>
    <link href="https://fly97.cn/p/nginx.conf%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3.html"/>
    <id>https://fly97.cn/p/nginx.conf%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3.html</id>
    <published>2020-08-12T05:28:00.000Z</published>
    <updated>2020-08-12T05:28:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要介绍了nginx的配置文件。</p><p><strong>摘要：</strong>Nginx 配置文件主要分成四部分：main（全局设置）、server（主机设置）、upstream（上游服务器设置，主要为反向代理、负载均衡相关配置）和 location（URL匹配特定位置后的设置）。main 部分设置的指令影响其他所有部分的设置；server 部分的指令主要用于制定虚拟主机域名、IP 和端口号；upstream 的指令用于设置一系列的后端服务器，设置反向代理及后端服务器的负载均衡；location 部分用于匹配网页位置（比如，根目录“/”，“/images”，等等）。他们之间的关系：server 继承 main，location 继承 server；upstream 既不会继承指令也不会被继承。</p><p><strong>关键词：</strong>Nginx</p><a id="more"></a><p>当前 nginx 支持的几个指令上下文()：</p><h4 id="nginx-conf-配置文件"><a href="#nginx-conf-配置文件" class="headerlink" title="nginx.conf 配置文件"></a>nginx.conf 配置文件</h4><hr><p>下面是 nginx.conf 详细的配置文件介绍（<strong>以下配置参数很多时候并不一定用的到，只是作为配置参数说明参考，可以看下面的通用版介绍</strong>）</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义Nginx运行的用户和用户组</span></span><br><span class="line"><span class="attribute">user</span> www www; </span><br><span class="line"></span><br><span class="line"><span class="comment">#nginx进程数，通常设置成和cpu的数量相等</span></span><br><span class="line"><span class="attribute">worker_processes</span> <span class="number">4</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment">#全局错误日志定义类型，[debug | info | notice | warn | error | crit]</span></span><br><span class="line"><span class="comment">#error_log  logs/error.log;</span></span><br><span class="line"><span class="comment">#error_log  logs/error.log  notice;</span></span><br><span class="line"><span class="comment">#error_log  logs/error.log  info;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#进程pid文件</span></span><br><span class="line"><span class="comment">#pid        logs/nginx.pid;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#指定进程可以打开的最大描述符：数目</span></span><br><span class="line"><span class="comment">#工作模式与连接数上限</span></span><br><span class="line"><span class="comment">##这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。</span></span><br><span class="line"><span class="comment">#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。</span></span><br><span class="line"><span class="attribute">worker_rlimit_nofile</span> <span class="number">65535</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">    <span class="comment">#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型</span></span><br><span class="line">    <span class="comment">#是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。</span></span><br><span class="line">    <span class="comment">#补充说明：</span></span><br><span class="line">    <span class="comment">#与apache相类，nginx针对不同的操作系统，有不同的事件模型</span></span><br><span class="line">    <span class="comment">#A）标准事件模型</span></span><br><span class="line">    <span class="comment">#Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll</span></span><br><span class="line">    <span class="comment">#B）高效事件模型</span></span><br><span class="line">    <span class="comment">#Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。</span></span><br><span class="line">    <span class="comment">#Epoll：使用于Linux内核2.6版本及以后的系统。</span></span><br><span class="line">    <span class="comment">#/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。</span></span><br><span class="line">    <span class="comment">#Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。</span></span><br><span class="line">    <span class="attribute">use</span> <span class="literal">epoll</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#单个进程最大连接数（最大连接数=连接数+进程数）</span></span><br><span class="line">    <span class="comment">#根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cup跑到100%就行。</span></span><br><span class="line">    worker_connections  <span class="number">1024</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#keepalive 超时时间</span></span><br><span class="line">    <span class="attribute">keepalive_timeout</span> <span class="number">60</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。</span></span><br><span class="line">    <span class="comment">#分页大小可以用命令getconf PAGESIZE 取得。</span></span><br><span class="line">    <span class="comment">#[root@web001 ~]# getconf PAGESIZE</span></span><br><span class="line">    <span class="comment">#但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。</span></span><br><span class="line">    <span class="attribute">client_header_buffer_size</span> <span class="number">4k</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。</span></span><br><span class="line">    <span class="attribute">open_file_cache</span> max=<span class="number">65535</span> inactive=<span class="number">60s</span>;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#这个是指多长时间检查一次缓存的有效信息。</span></span><br><span class="line">    <span class="comment">#语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.</span></span><br><span class="line">    <span class="attribute">open_file_cache_valid</span> <span class="number">80s</span>;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。</span></span><br><span class="line">    <span class="comment">#语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location  这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态.</span></span><br><span class="line">    <span class="attribute">open_file_cache_min_uses</span> <span class="number">1</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误.</span></span><br><span class="line">    <span class="attribute">open_file_cache_errors</span> <span class="literal">on</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#设定http服务器，利用它的反向代理功能提供负载均衡支持</span></span><br><span class="line">http&#123;</span><br><span class="line">    <span class="comment">#文件扩展名与文件类型映射表</span></span><br><span class="line">    <span class="attribute">include</span> mime.types;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#默认文件类型</span></span><br><span class="line">    <span class="attribute">default_type</span> application/octet-stream;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#默认编码</span></span><br><span class="line">    <span class="attribute">charset</span> utf-<span class="number">8</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#服务器名字的hash表大小</span></span><br><span class="line">    <span class="comment">#保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.</span></span><br><span class="line">    <span class="attribute">server_names_hash_bucket_size</span> <span class="number">128</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。</span></span><br><span class="line">    <span class="attribute">client_header_buffer_size</span> <span class="number">32k</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。</span></span><br><span class="line">    <span class="attribute">large_client_header_buffers</span> <span class="number">4</span> <span class="number">64k</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#设定通过nginx上传文件的大小</span></span><br><span class="line">    <span class="attribute">client_max_body_size</span> <span class="number">8m</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。</span></span><br><span class="line">    <span class="comment">#sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。</span></span><br><span class="line">    <span class="attribute">sendfile</span> <span class="literal">on</span>;</span><br><span class="line">    </span><br><span class="line">     <span class="comment">#开启目录列表访问，合适下载服务器，默认关闭。</span></span><br><span class="line">    <span class="attribute">autoindex</span> <span class="literal">on</span>;</span><br><span class="line">    </span><br><span class="line">      <span class="comment">#此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用</span></span><br><span class="line">    <span class="attribute">tcp_nopush</span> <span class="literal">on</span>;</span><br><span class="line">     </span><br><span class="line">    <span class="attribute">tcp_nodelay</span> <span class="literal">on</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#长连接超时时间，单位是秒</span></span><br><span class="line">    <span class="attribute">keepalive_timeout</span> <span class="number">120</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。</span></span><br><span class="line">    <span class="attribute">fastcgi_connect_timeout</span> <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">fastcgi_send_timeout</span> <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">fastcgi_read_timeout</span> <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">fastcgi_buffer_size</span> <span class="number">64k</span>;</span><br><span class="line">    <span class="attribute">fastcgi_buffers</span> <span class="number">4</span> <span class="number">64k</span>;</span><br><span class="line">    <span class="attribute">fastcgi_busy_buffers_size</span> <span class="number">128k</span>;</span><br><span class="line">    <span class="attribute">fastcgi_temp_file_write_size</span> <span class="number">128k</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#gzip模块设置</span></span><br><span class="line">    <span class="attribute">gzip</span> <span class="literal">on</span>; <span class="comment">#开启gzip压缩输出</span></span><br><span class="line">    <span class="attribute">gzip_min_length</span> <span class="number">1k</span>;    <span class="comment">#最小压缩文件大小</span></span><br><span class="line">    <span class="attribute">gzip_buffers</span> <span class="number">4</span> <span class="number">16k</span>;    <span class="comment">#压缩缓冲区</span></span><br><span class="line">    <span class="attribute">gzip_http_version</span> <span class="number">1</span>.<span class="number">0</span>; <span class="comment">#压缩版本（默认1.1，前端如果是squid2.5请使用1.0）</span></span><br><span class="line">    <span class="attribute">gzip_comp_level</span> <span class="number">2</span>;     <span class="comment">#压缩等级</span></span><br><span class="line">    <span class="attribute">gzip_types</span> text/plain application/x-javascript text/css application/xml;    <span class="comment">#压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。</span></span><br><span class="line">    <span class="attribute">gzip_vary</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#开启限制IP连接数的时候需要使用</span></span><br><span class="line">    <span class="comment">#limit_zone crawler $binary_remote_addr 10m;</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#负载均衡配置</span></span><br><span class="line">    <span class="attribute">upstream</span> piao.jd.com &#123;</span><br><span class="line">     </span><br><span class="line">        <span class="comment">#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。</span></span><br><span class="line">        <span class="attribute">server</span> <span class="number">192.168.80.121:80</span> weight=<span class="number">3</span>;</span><br><span class="line">        <span class="attribute">server</span> <span class="number">192.168.80.122:80</span> weight=<span class="number">2</span>;</span><br><span class="line">        <span class="attribute">server</span> <span class="number">192.168.80.123:80</span> weight=<span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#nginx的upstream目前支持4种方式的分配</span></span><br><span class="line">        <span class="comment">#1、轮询（默认）</span></span><br><span class="line">        <span class="comment">#每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</span></span><br><span class="line">        <span class="comment">#2、weight</span></span><br><span class="line">        <span class="comment">#指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。</span></span><br><span class="line">        <span class="comment">#例如：</span></span><br><span class="line">        <span class="comment">#upstream bakend &#123;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.14 weight=10;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.15 weight=10;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#2、ip_hash</span></span><br><span class="line">        <span class="comment">#每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</span></span><br><span class="line">        <span class="comment">#例如：</span></span><br><span class="line">        <span class="comment">#upstream bakend &#123;</span></span><br><span class="line">        <span class="comment">#    ip_hash;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.14:88;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.15:80;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#3、fair（第三方）</span></span><br><span class="line">        <span class="comment">#按后端服务器的响应时间来分配请求，响应时间短的优先分配。</span></span><br><span class="line">        <span class="comment">#upstream backend &#123;</span></span><br><span class="line">        <span class="comment">#    server server1;</span></span><br><span class="line">        <span class="comment">#    server server2;</span></span><br><span class="line">        <span class="comment">#    fair;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#4、url_hash（第三方）</span></span><br><span class="line">        <span class="comment">#按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。</span></span><br><span class="line">        <span class="comment">#例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法</span></span><br><span class="line">        <span class="comment">#upstream backend &#123;</span></span><br><span class="line">        <span class="comment">#    server squid1:3128;</span></span><br><span class="line">        <span class="comment">#    server squid2:3128;</span></span><br><span class="line">        <span class="comment">#    hash $request_uri;</span></span><br><span class="line">        <span class="comment">#    hash_method crc32;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#tips:</span></span><br><span class="line">        <span class="comment">#upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123;</span></span><br><span class="line">        <span class="comment">#    ip_hash;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:9090 down;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:8080 weight=2;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:6060;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:7070 backup;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#在需要使用负载均衡的server中增加 proxy_pass http://bakend/;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#每个设备的状态设置为:</span></span><br><span class="line">        <span class="comment">#1.down表示单前的server暂时不参与负载</span></span><br><span class="line">        <span class="comment">#2.weight为weight越大，负载的权重就越大。</span></span><br><span class="line">        <span class="comment">#3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误</span></span><br><span class="line">        <span class="comment">#4.fail_timeout:max_fails次失败后，暂停的时间。</span></span><br><span class="line">        <span class="comment">#5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#nginx支持同时设置多组的负载均衡，用来给不用的server来使用。</span></span><br><span class="line">        <span class="comment">#client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug</span></span><br><span class="line">        <span class="comment">#client_body_temp_path设置记录文件的目录 可以设置最多3层目录</span></span><br><span class="line">        <span class="comment">#location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#虚拟主机的配置</span></span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="comment">#监听端口</span></span><br><span class="line">        <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#域名可以有多个，用空格隔开</span></span><br><span class="line">        <span class="attribute">server_name</span> www.jd.com jd.com;</span><br><span class="line">        <span class="comment">#默认入口文件名称</span></span><br><span class="line">        <span class="attribute">index</span> index.html index.htm index.php;</span><br><span class="line">        <span class="attribute">root</span> /data/www/jd;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#对******进行负载均衡</span></span><br><span class="line">        <span class="attribute">location</span> <span class="regexp">~ .*.(php|php5)?$</span></span><br><span class="line"><span class="regexp"></span>        &#123;</span><br><span class="line">            <span class="attribute">fastcgi_pass</span> <span class="number">127.0.0.1:9000</span>;</span><br><span class="line">            <span class="attribute">fastcgi_index</span> index.php;</span><br><span class="line">            <span class="attribute">include</span> fastcgi.conf;</span><br><span class="line">        &#125;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#图片缓存时间设置</span></span><br><span class="line">        <span class="attribute">location</span> <span class="regexp">~ .*.(gif|jpg|jpeg|png|bmp|swf)$</span></span><br><span class="line"><span class="regexp"></span>        &#123;</span><br><span class="line">            <span class="attribute">expires</span> <span class="number">10d</span>;</span><br><span class="line">        &#125;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#JS和CSS缓存时间设置</span></span><br><span class="line">        <span class="attribute">location</span> <span class="regexp">~ .*.(js|css)?$</span></span><br><span class="line"><span class="regexp"></span>        &#123;</span><br><span class="line">            <span class="attribute">expires</span> <span class="number">1h</span>;</span><br><span class="line">        &#125;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#日志格式设定</span></span><br><span class="line">        <span class="comment">#$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；</span></span><br><span class="line">        <span class="comment">#$remote_user：用来记录客户端用户名称；</span></span><br><span class="line">        <span class="comment">#$time_local： 用来记录访问时间与时区；</span></span><br><span class="line">        <span class="comment">#$request： 用来记录请求的url与http协议；</span></span><br><span class="line">        <span class="comment">#$status： 用来记录请求状态；成功是200，</span></span><br><span class="line">        <span class="comment">#$body_bytes_sent ：记录发送给客户端文件主体内容大小；</span></span><br><span class="line">        <span class="comment">#$http_referer：用来记录从那个页面链接访问过来的；</span></span><br><span class="line">        <span class="comment">#$http_user_agent：记录客户浏览器的相关信息；</span></span><br><span class="line">        <span class="comment">#通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。</span></span><br><span class="line">        <span class="attribute">log_format</span> access <span class="string">&#x27;<span class="variable">$remote_addr</span> - <span class="variable">$remote_user</span> [<span class="variable">$time_local</span>] &quot;<span class="variable">$request</span>&quot; &#x27;</span></span><br><span class="line">        <span class="string">&#x27;<span class="variable">$status</span> <span class="variable">$body_bytes_sent</span> &quot;<span class="variable">$http_referer</span>&quot; &#x27;</span></span><br><span class="line">        <span class="string">&#x27;&quot;<span class="variable">$http_user_agent</span>&quot; <span class="variable">$http_x_forwarded_for</span>&#x27;</span>;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#定义本虚拟主机的访问日志</span></span><br><span class="line">        <span class="attribute">access_log</span>  /usr/local/nginx/logs/host.access.log  main;</span><br><span class="line">        <span class="attribute">access_log</span>  /usr/local/nginx/logs/host.access.<span class="number">404</span>.log  log404;</span><br><span class="line">         </span><br><span class="line">        <span class="comment">#对 &quot;/connect-controller&quot; 启用反向代理</span></span><br><span class="line">        <span class="attribute">location</span> /connect-controller &#123;</span><br><span class="line">            <span class="attribute">proxy_pass</span> http://127.0.0.1:88; <span class="comment">#请注意此处端口号不能与虚拟主机监听的端口号一样（也就是server监听的端口）</span></span><br><span class="line">            <span class="attribute">proxy_redirect</span> <span class="literal">off</span>;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">             </span><br><span class="line">            <span class="comment">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span></span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">             </span><br><span class="line">            <span class="comment">#以下是一些反向代理的配置，可选。</span></span><br><span class="line">            <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#允许客户端请求的最大单文件字节数</span></span><br><span class="line">            <span class="attribute">client_max_body_size</span> <span class="number">10m</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#缓冲区代理缓冲用户端请求的最大字节数，</span></span><br><span class="line">            <span class="comment">#如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。</span></span><br><span class="line">            <span class="comment">#无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误</span></span><br><span class="line">            <span class="attribute">client_body_buffer_size</span> <span class="number">128k</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#表示使nginx阻止HTTP应答代码为400或者更高的应答。</span></span><br><span class="line">            <span class="attribute">proxy_intercept_errors</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#后端服务器连接的超时时间_发起握手等候响应超时时间</span></span><br><span class="line">            <span class="comment">#nginx跟后端服务器连接超时时间(代理连接超时)</span></span><br><span class="line">            <span class="attribute">proxy_connect_timeout</span> <span class="number">90</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#后端服务器数据回传时间(代理发送超时)</span></span><br><span class="line">            <span class="comment">#后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据</span></span><br><span class="line">            <span class="attribute">proxy_send_timeout</span> <span class="number">90</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#连接成功后，后端服务器响应时间(代理接收超时)</span></span><br><span class="line">            <span class="comment">#连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）</span></span><br><span class="line">            <span class="attribute">proxy_read_timeout</span> <span class="number">90</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#设置代理服务器（nginx）保存用户头信息的缓冲区大小</span></span><br><span class="line">            <span class="comment">#设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小</span></span><br><span class="line">            <span class="attribute">proxy_buffer_size</span> <span class="number">4k</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#proxy_buffers缓冲区，网页平均在32k以下的设置</span></span><br><span class="line">            <span class="comment">#设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k</span></span><br><span class="line">            <span class="attribute">proxy_buffers</span> <span class="number">4</span> <span class="number">32k</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#高负荷下缓冲大小（proxy_buffers*2）</span></span><br><span class="line">            <span class="attribute">proxy_busy_buffers_size</span> <span class="number">64k</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长</span></span><br><span class="line">            <span class="comment">#设定缓存文件夹大小，大于这个值，将从upstream服务器传</span></span><br><span class="line">            <span class="attribute">proxy_temp_file_write_size</span> <span class="number">64k</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#本地动静分离反向代理配置</span></span><br><span class="line">        <span class="comment">#所有jsp的页面均交由tomcat或resin处理</span></span><br><span class="line">        <span class="attribute">location</span> <span class="regexp">~ .(jsp|jspx|do)?$</span> &#123;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">            <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">            <span class="attribute">proxy_pass</span> http://127.0.0.1:8080;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文主要介绍了nginx的配置文件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要：&lt;/strong&gt;Nginx 配置文件主要分成四部分：main（全局设置）、server（主机设置）、upstream（上游服务器设置，主要为反向代理、负载均衡相关配置）和 location（URL匹配特定位置后的设置）。main 部分设置的指令影响其他所有部分的设置；server 部分的指令主要用于制定虚拟主机域名、IP 和端口号；upstream 的指令用于设置一系列的后端服务器，设置反向代理及后端服务器的负载均衡；location 部分用于匹配网页位置（比如，根目录“/”，“/images”，等等）。他们之间的关系：server 继承 main，location 继承 server；upstream 既不会继承指令也不会被继承。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词：&lt;/strong&gt;Nginx&lt;/p&gt;</summary>
    
    
    
    
    <category term="nginx" scheme="https://fly97.cn/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>安装Fish自动匹配历史命令</title>
    <link href="https://fly97.cn/p/%E5%AE%89%E8%A3%85Fish%E8%87%AA%E5%8A%A8%E5%8C%B9%E9%85%8D%E5%8E%86%E5%8F%B2%E5%91%BD%E4%BB%A4.html"/>
    <id>https://fly97.cn/p/%E5%AE%89%E8%A3%85Fish%E8%87%AA%E5%8A%A8%E5%8C%B9%E9%85%8D%E5%8E%86%E5%8F%B2%E5%91%BD%E4%BB%A4.html</id>
    <published>2020-08-10T13:50:00.000Z</published>
    <updated>2020-08-10T13:50:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍了Fish的使用，使用Fish可以根据输入自动匹配历史命令。</p><p><strong>摘要</strong>：Fish的官网宣传语是 Finally, a command line shell for the 90s。 翻译过来就是 Fish shell 是一个为90后准备的 shell。有人说：“二逼青年用bash，普通青年用zsh，文艺青年用fish。”<br>其次由于zsh 的速度实在是太慢，所以决定换用fish，fish速度快，智能提示强大。</p><p><strong>关键字</strong>：Fish</p><a id="more"></a><h4 id="Fish入门使用"><a href="#Fish入门使用" class="headerlink" title="Fish入门使用"></a>Fish入门使用</h4><h5 id="Ubuntu安装Fish"><a href="#Ubuntu安装Fish" class="headerlink" title="Ubuntu安装Fish"></a>Ubuntu安装Fish</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apt-get install software-properties-common</span><br><span class="line">sudo apt-add-repository ppa:fish-shell/release-2</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install fish</span><br><span class="line"><span class="comment">#切换到fish</span></span><br><span class="line"><span class="built_in">echo</span> /usr/bin/fish | sudo tee -a /etc/shells</span><br><span class="line">sudo chsh -s /usr/bin/fish &amp;&amp; fish</span><br></pre></td></tr></table></figure><p>fish的鲜明特征在于安装时已经默认集成了很多需要的功能。<br>比如：</p><ul><li>命令行语法高亮，错误会显示红色</li><li>智能提示</li><li>可以使用web网页的进行终端配置</li></ul><p>fish 有智能提示，一个命令一旦输入过一次，会自动显示上一次的全部命令，细心一点会发现会有一层灰色的字体表示上一次的命令，按<code>Ctrl+F</code>或者 右方向键<code>→</code>， 即可自动补全。</p><p><img src="https://ftp.fly97.cn/image/20200811_144927.gif"></p><h5 id="网页配置Fish"><a href="#网页配置Fish" class="headerlink" title="网页配置Fish"></a>网页配置Fish</h5><p><code>fish_config</code> 可以直接跳出网页版本配置fish的界面。</p><p>web版本可以设置主题， 推荐其中的”Tomorrow Night”主题颜色。</p><p><img src="https://ftp.fly97.cn/image/2027280-11b7a5729b03227b.webp" alt="img"></p><p>选择想要的主题，然后点击set theme即可设置主题。<br>在命令里按enter 即可退出web版本的界面。</p><p>在prompt里面可以自己选择fish终端的主题。</p><p><img src="https://ftp.fly97.cn/image/2027280-3f8729b449ea454d.webp" alt="img"></p><h4 id="兼容Bash"><a href="#兼容Bash" class="headerlink" title="兼容Bash"></a>兼容Bash</h4><p>由于fish 很多<strong>不兼容</strong>bash的功能导致了很多脚本无法运行，这一点是很多人吐槽fish的地方，我们需要一种方式来运行bash脚本。</p><p>比如</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arc land --onto `git rev-parse --abbrev-ref HEAD` </span><br></pre></td></tr></table></figure><p>只需要在前面添加一个bash -c 命令即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -c <span class="string">&quot;arc land --onto `git rev-parse --abbrev-ref HEAD`&quot;</span></span><br></pre></td></tr></table></figure><p>顺手加个alias就更方便了，可以直接在命令行里使用命令<code>arcl</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">alias</span> arcl bash -c <span class="string">&quot;arc land --onto `git rev-parse --abbrev-ref HEAD`&quot;</span></span><br></pre></td></tr></table></figure><p>对于脚本文件，比如我将需要执行的命令或文件放到<code>repomerge.sh</code></p><p>在~/.config/fish/config.fish添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">alias</span> up <span class="string">&quot;bash -c /usr/bin/repomerge.sh&quot;</span></span><br></pre></td></tr></table></figure><p>然后就可以自由的使用up命令了</p><p>其中function fish_prompt 函数用于定义fish终端的显示样式。</p><p>我们只需要写一个fish_prompt函数即可。集成了git的分支名称以及当前的变化。</p><p>显示的样式如下：</p><p><img src="https://ftp.fly97.cn/image/2027280-2c1a98068158e5fd.webp" alt="img"></p><p><strong>说明:<br> ✔代表当前git项目是干净的。<br> %1 表示有一个文件未追踪<br> +1 表示一个文件已暂存</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 终端显示样式的配置</span></span><br><span class="line"><span class="keyword">function</span> fish_prompt --description <span class="string">&#x27;Write out the prompt&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> not <span class="built_in">set</span> -q __fish_prompt_normal</span><br><span class="line">        <span class="built_in">set</span> -g __fish_prompt_normal (set_color normal)</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    __fish_git_prompt &gt;/dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> git_is_repo</span><br><span class="line">        <span class="keyword">if</span> not <span class="built_in">set</span> -q __git_cb</span><br><span class="line">            <span class="built_in">set</span> __git_cb (set_color blue)<span class="string">&quot; (&quot;</span>(set_color brred)(git branch | grep \* | sed <span class="string">&#x27;s/* //&#x27;</span>) (set_color -o bryellow)(__fish_git_prompt_informative_status)(set_color blue)<span class="string">&quot;)&quot;</span></span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> not <span class="built_in">set</span> -q __fish_prompt_cwd</span><br><span class="line">        <span class="built_in">set</span> -g __fish_prompt_cwd (set_color <span class="variable">$fish_color_cwd</span>)</span><br><span class="line">    end</span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&#x27;%s%s%s%s &#x27;</span> <span class="string">&quot;<span class="variable">$__fish_prompt_cwd</span>&quot;</span> (prompt_pwd) <span class="string">&quot;<span class="variable">$__fish_prompt_normal</span>&quot;</span> <span class="variable">$__git_cb</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure><h4 id="隐藏欢迎语"><a href="#隐藏欢迎语" class="headerlink" title="隐藏欢迎语"></a>隐藏欢迎语</h4><p>在confin.sh文件里添加如下函数即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> fish_greeting</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h4 id="其他配置"><a href="#其他配置" class="headerlink" title="其他配置"></a>其他配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">alias</span> l <span class="string">&quot;ll&quot;</span></span><br><span class="line"><span class="built_in">alias</span> dir <span class="string">&quot;dde-file-manager . &amp;&quot;</span></span><br><span class="line"><span class="built_in">alias</span> docker <span class="string">&quot;sudo docker&quot;</span></span><br><span class="line"><span class="built_in">alias</span> apt <span class="string">&quot;sudo apt&quot;</span></span><br></pre></td></tr></table></figure><p>作者：iceqing<br>链接：<a href="https://www.jianshu.com/p/bf03bce60987">https://www.jianshu.com/p/bf03bce60987</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文介绍了Fish的使用，使用Fish可以根据输入自动匹配历史命令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;：Fish的官网宣传语是 Finally, a command line shell for the 90s。 翻译过来就是 Fish shell 是一个为90后准备的 shell。有人说：“二逼青年用bash，普通青年用zsh，文艺青年用fish。”&lt;br&gt;其次由于zsh 的速度实在是太慢，所以决定换用fish，fish速度快，智能提示强大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键字&lt;/strong&gt;：Fish&lt;/p&gt;</summary>
    
    
    
    
    <category term="Linux" scheme="https://fly97.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>安装autojump自动切换目录</title>
    <link href="https://fly97.cn/p/%E5%AE%89%E8%A3%85autojump%E8%87%AA%E5%8A%A8%E5%88%87%E6%8D%A2%E7%9B%AE%E5%BD%95.html"/>
    <id>https://fly97.cn/p/%E5%AE%89%E8%A3%85autojump%E8%87%AA%E5%8A%A8%E5%88%87%E6%8D%A2%E7%9B%AE%E5%BD%95.html</id>
    <published>2020-08-10T13:50:00.000Z</published>
    <updated>2020-08-10T13:50:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍了autojump的使用，使用autojump可以很方便地切换目录。</p><p><strong>摘要</strong>：熟悉Linux 的小伙伴们都知道，在终端下需要使用命令<code>cd</code>切换目录。对于多层目录，还需要不停的用使用<code>cd</code>命令或者 Tab 键补齐，如果目录下文件夹过多，还需要使用<code>ls</code>查看当前目录下的文件。<a href="https://github.com/wting/autojump">autojump </a>是浏览文件系统的一种更快的方法。它通过维护命令行中最常用的目录的数据库来工作。autojump 是通过记录进入过的目录到数据库来实现的，所以必须是曾经进入过的目录才能跳转。</p><p><strong>关键字</strong>：autojump</p><a id="more"></a><h4 id="Linux下安装"><a href="#Linux下安装" class="headerlink" title="Linux下安装"></a>Linux下安装</h4><h5 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a>源码安装</h5><p>克隆以下仓库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/wting/autojump.git</span><br></pre></td></tr></table></figure><p>coding分流</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://e.coding.net/fly97/github-projects/autojump.git</span><br></pre></td></tr></table></figure><p>执行安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> autojump</span><br><span class="line">chmod +x install.py</span><br><span class="line">./install.py</span><br></pre></td></tr></table></figure><h5 id="fish-shell的设置"><a href="#fish-shell的设置" class="headerlink" title="fish shell的设置"></a>fish shell的设置</h5><p>执行以下命令以创建fish shell的配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;if test -f /root/.autojump/share/autojump/autojump.fish; . /root/.autojump/share/autojump/autojump.fish; end&quot;</span> &gt;&gt; ~/.config/fish/config.fish</span><br></pre></td></tr></table></figure><h5 id="修改环境变量"><a href="#修改环境变量" class="headerlink" title="修改环境变量"></a>修改环境变量</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export PATH=&quot;</span><span class="variable">$PATH</span>:/root/.autojump/bin<span class="string">&quot; &gt; /etc/profile</span></span><br></pre></td></tr></table></figure><h5 id="执行以下命令检查是否正常运行"><a href="#执行以下命令检查是否正常运行" class="headerlink" title="执行以下命令检查是否正常运行"></a>执行以下命令检查是否正常运行</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">j --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200811140853462.png" alt="image-20200811140853462"></p><h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="查看-autojump-存储的目录的状态"><a href="#查看-autojump-存储的目录的状态" class="headerlink" title="查看 autojump 存储的目录的状态"></a>查看 <code>autojump</code> 存储的目录的状态</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">j -s</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200811142040440.png" alt="image-20200811142040440"></p><h5 id="查看使用帮助"><a href="#查看使用帮助" class="headerlink" title="查看使用帮助"></a>查看使用帮助</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">j -h</span><br></pre></td></tr></table></figure><p><img src="https://ftp.fly97.cn/image/image-20200811142133380.png" alt="image-20200811142133380"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文介绍了autojump的使用，使用autojump可以很方便地切换目录。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;：熟悉Linux 的小伙伴们都知道，在终端下需要使用命令&lt;code&gt;cd&lt;/code&gt;切换目录。对于多层目录，还需要不停的用使用&lt;code&gt;cd&lt;/code&gt;命令或者 Tab 键补齐，如果目录下文件夹过多，还需要使用&lt;code&gt;ls&lt;/code&gt;查看当前目录下的文件。&lt;a href=&quot;https://github.com/wting/autojump&quot;&gt;autojump &lt;/a&gt;是浏览文件系统的一种更快的方法。它通过维护命令行中最常用的目录的数据库来工作。autojump 是通过记录进入过的目录到数据库来实现的，所以必须是曾经进入过的目录才能跳转。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键字&lt;/strong&gt;：autojump&lt;/p&gt;</summary>
    
    
    
    
    <category term="Linux" scheme="https://fly97.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>深度学习常见损失函数</title>
    <link href="https://fly97.cn/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.html"/>
    <id>https://fly97.cn/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.html</id>
    <published>2020-08-09T05:00:00.000Z</published>
    <updated>2020-08-09T05:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>我们所说的优化，即优化网络权值使得损失函数值变小。但是，损失函数值变小是否能代表模型的分类/回归精度变高呢？那么多种损失函数，应该如何选择呢？</p><a id="more"></a><h4 id="L1范数损失-L1Loss"><a href="#L1范数损失-L1Loss" class="headerlink" title="L1范数损失  L1Loss"></a>L1范数损失  L1Loss</h4><p>功能： 计算 output 和 target 之差的绝对值，可选返回同维度的tensor或者是一个标量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.L1Loss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><blockquote><p>reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。</p></blockquote><h4 id="均方损失误差-MESLoss"><a href="#均方损失误差-MESLoss" class="headerlink" title="均方损失误差 MESLoss"></a>均方损失误差 MESLoss</h4><p>功能： 计算 output 和 target 之差的平方，可选返回同维度的tensor或者是一个标量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MSELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><blockquote><p>reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。</p></blockquote><h4 id="交叉熵损失-CrossEntropyLoss"><a href="#交叉熵损失-CrossEntropyLoss" class="headerlink" title="交叉熵损失 CrossEntropyLoss"></a>交叉熵损失 CrossEntropyLoss</h4><p>功能： 将输入经过 softmax 激活函数之后，再计算其与 target 的交叉熵损失。即该方法将 nn.LogSoftmax() 和 nn.NLLLoss() 进行了结合。严格意义上的交叉熵损失函数应该是 nn.NLLLoss()。</p><p>当训练有 C 个类别的分类问题时很有效，可选参数<code>weight</code>必须是一个1维<code>Tensor</code>，权重将被分配给各个类别。对于不平衡的训练集非常有效。</p><p>在多分类任务中，经常采用 softmax 激活函数+交叉熵损失函数。因为交叉熵描述了两个<strong>概率分布</strong>的差异，然而神经网络输出的是向量，并不是概率分布的形式。所以需要 softmax 激活函数将一个向量进行“归一化”成概率分布的形式，再采用交叉熵损失函数计算 loss.<br>$$<br>loss(x,class)=weight[class]\left(-x[class]+log \left(\sum_{j}^{}exp(x[    j])\right)\right)<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CrossEntropyLoss(weight=<span class="literal">None</span>,ignore_index=<span class="number">-100</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><blockquote><p>weight (Tensor, optional) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor</p><p>ignore_index (int, optional) – 设置一个目标值, 该目标值会被忽略, 从而不会影响到 输入的梯度。</p><p>reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。</p></blockquote><h4 id="KL散度损失-KLDivLoss"><a href="#KL散度损失-KLDivLoss" class="headerlink" title="KL散度损失 KLDivLoss"></a>KL散度损失 KLDivLoss</h4><p>功能：计算 input 和 target 之间的 KL 散度。KL散度可用于衡量不同的连续分布之间的距离，在连续的输出分布的空间上(离散采样)上进行直接回归时<strong>很有效</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.KLDivLoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><blockquote><p>reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。</p></blockquote><blockquote><p>补充：KL散度 KL散度( Kullback–Leibler divergence) 又称为相对熵(Relative Entropy)，用于描述两个概率分布之间的差异。计算公式(离散时)：</p><p>其中p表示真实分布，q表示p的拟合分布， D(P||Q)表示当用概率分布q来拟合真实分布p时，产生的信息损耗。这里的信息损耗，可以理解为损失，损失越低，拟合分布q越接近真实分布p。同时也可以从另外一个角度上观察这个公式，即计算的是 p 与 q 之间的对数差在 p 上的期望值。 特别注意，D(p||q) ≠ D(q||p)， 其不具有对称性，因此不能称为K-L距离。</p><p><strong>信息熵 = 交叉熵 - 相对熵</strong> 从信息论角度观察三者，其关系为信息熵 = 交叉熵 - 相对熵。在机器学习中，当训练数据固定，最小化相对熵 D(p||q) 等价于最小化交叉熵 H(p,q) 。</p></blockquote><p>使用注意事项： 要想获得真正的KL散度，需要如下操作：</p><ol><li><p>reduce = True ；size_average=False</p></li><li><p>计算得到的 loss 要对 batch 进行求平均</p></li></ol><h4 id="二进制交叉熵损失-BCELoss"><a href="#二进制交叉熵损失-BCELoss" class="headerlink" title="二进制交叉熵损失 BCELoss"></a>二进制交叉熵损失 BCELoss</h4><p>功能： 二分类任务时的交叉熵计算函数。此函数可以认为是nn.CrossEntropyLoss函数的特例。其分类限定为二分类，y必须是{0,1}。还需要注意的是，input应该为概率分布的形式，这样才符合交叉熵的应用。所以在BCELoss之前，input一般为sigmoid激活层的输出。该损失函数在自编码器中常用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BCELoss(weight=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><blockquote><p>weight (Tensor, optional) – 自定义的每个 batch 元素的 loss 的权重. 必须是一个长度为 “nbatch” 的 的 Tensor</p></blockquote><h4 id="BCEWithLogitsLoss"><a href="#BCEWithLogitsLoss" class="headerlink" title="BCEWithLogitsLoss"></a>BCEWithLogitsLoss</h4><p>功能： 将Sigmoid与BCELoss结合，类似于CrossEntropyLoss(将nn.LogSoftmax()和 nn.NLLLoss()进行结合）。即input会经过Sigmoid激活函数，将input变成概率分布的形式。 计算公式：    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BCEWithLogitsLoss(weight=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, pos_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><blockquote><p>weight (Tensor, optional) – 自定义的每个 batch 元素的 loss 的权重. 必须是一个长度 为 “nbatch” 的 Tensor</p></blockquote><h4 id="MarginRankingLoss"><a href="#MarginRankingLoss" class="headerlink" title="MarginRankingLoss"></a>MarginRankingLoss</h4><p>功能： 计算两个向量之间的相似度，当两个向量之间的距离大于margin，则loss为正，小于margin，loss为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MarginRankingLoss(margin=<span class="number">0.0</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><p>对于 mini-batch (小批量) 中每个实例的损失函数如下：<br>$$<br>loss(x,y)=max(0,-y*(x1-x2)+margin)<br>$$<br>参数：</p><blockquote><p>margin：默认值是0</p></blockquote><h4 id="HingeEmbeddingLoss"><a href="#HingeEmbeddingLoss" class="headerlink" title="HingeEmbeddingLoss"></a>HingeEmbeddingLoss</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.HingeEmbeddingLoss(margin=<span class="number">1.0</span>,  reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><p>功能： 未知。主要用于衡量两个输入是否相似。 used for learning nonlinear embeddings or semi-supervised 。</p><p>转载自：<a href="https://zhuanlan.zhihu.com/p/61379965">https://zhuanlan.zhihu.com/p/61379965</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们所说的优化，即优化网络权值使得损失函数值变小。但是，损失函数值变小是否能代表模型的分类/回归精度变高呢？那么多种损失函数，应该如何选择呢？&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器学习" scheme="https://fly97.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习基本概念03</title>
    <link href="https://fly97.cn/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B503.html"/>
    <id>https://fly97.cn/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B503.html</id>
    <published>2020-08-07T13:50:00.000Z</published>
    <updated>2020-08-07T13:50:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习中的归纳偏好。</p><a id="more"></a><h4 id="归纳偏好"><a href="#归纳偏好" class="headerlink" title="归纳偏好"></a>归纳偏好</h4><p>通过学习得到的模型对应了假设空间的一个假设，于是，上文中的西瓜版本空间给我们带来了一个麻烦：现在有三个与训练集一致的假设，但与他们对应的模型在面临新样本的时候，却会产生不同的输出。例如，对色泽=青绿；根蒂=蜷缩；敲声=沉闷这个新收来的瓜，如果我们采用的是“好瓜《=》（色泽=<em>）^（敲声=\</em>)”。那么会把新瓜判断为好瓜，而如果采用了另外两个假设，则判断的结果将不是好瓜，那么，应该采用哪一个模型（或假设）呢？</p><p>​    若仅有上表中训练样本，则无法断定上述三个假设哪一个“更好”。然而，对于一个具体的学习算法而言，他必须要产生一个模型。这时，学习算法本身的“偏好”就会起到关键的作用。例如，若我们的算法喜欢尽可能特殊的模型，则他会选择“好瓜《=》（色泽=*）^（根蒂=蜷缩）^(敲声=浊响)”；但若我们的算法喜欢“尽可能一般”的模型，并且由于某种原因它更相信“根蒂”，则它会选择“好瓜《=》（色泽=<em>）^（根蒂=蜷缩）^(敲声=\</em>)”，机器学习算法在学习过程中对某种类型假设的偏好，称为“归纳偏好”(inductive bias)，或称为“偏好”。</p><blockquote><p>尽可能特殊即“适用情况尽可能少”；尽可能一般即“使用情况尽可能多”。</p><p>对“根蒂”还是对“敲声”更重视，看起来和属性选择，亦称为“特征选择”(feature selection)有关，但需注意的是，机器学习中的特征选择仍是基于对训练样本的模型的分析进行的，而在此处我们并非基于特征选择做出对根蒂的重视；这里对“根蒂”的信赖可视为基于某种领域的知识而产生的归纳偏好关于特征选择方面的内容可以参加后续的更新。</p></blockquote><p>任何一个有效的机器学习算法未必有其归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设所迷惑，而无法产生确定的学习结果。可以想象，如果没有偏好，我们的西瓜学习算法产生的模型每次在进行预测时随机抽选训练集上的等效假设，那么对这个新瓜————–学得模型时而告诉我们他是好的，时而告诉我们他是不好的，这样的学习结果显然没有意义。</p><p>归纳偏好的作用在图1.3这个回归学习图示中可能更直观，这里的每个训练样本是图中的一个点(x,y)，要学得一个与训练集一致的模型，相当于找到一条穿过所有训练样本点的曲线。显然，对有限个样本点组成的训练集，存在着很多条曲线与其一致，我们的学习算法必须有某种偏好，才能产出它认为”正确”的模型。例如，若认为相似的样本应有相似的输出(例如，在各种属性上都很像的西瓜，成熟程度应该比较接近)，则对应的学习算法可能偏好图1.3中比较“平滑”的曲线$A$而不是比较“崎岖”的曲线$B$.</p><p>归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或”价值观”.那么，有没有一般性的原则来引导算法确立“正确的”偏好呢？<strong>“奥卡姆剃刀”（Occam’s razor)**是一种常用的、自然科学研究中最基本的原则，即</strong>“若有若干个假设与观察一致，则选最简单的那个”**.如果采用这个原则，并且假设我们认为“更平滑”意味着“更简单”(例如曲线A更容易描述，其方程式是$y = -x_2+6x+1$，而曲线$B$则要复杂得多)，则在图1.3中我们会自然地偏好“平滑”的曲线$A$.</p><p>然而，奥卡姆剃刀并非唯一可行的原则，退一步说，即便假定我们是奥卡姆剃刀的铁杆拥簇，也需注意到，奥卡姆剃刀本身存在不同的诠释，使用奥卡姆剃刀原则并不平凡。例如对我们已经很熟悉的西瓜问题来说，“假设1：好瓜&lt;-&gt;(色泽=*)^(根蒂=蜷缩)^(敲声=浊响)”和“假设2：好瓜&lt;-&gt;(色泽=*)^(根蒂=蜷缩)^(敲声=*)”这两个假设，哪一个更“简单”呢？这个问题并不简单，需要借助其他机制才能解决.</p><p>事实上，归纳偏好对应了学习算法本身所作出的关于”什么样的模型更好”的假设.在具体的实现问题中，这个假设是否成立，即算法的归纳偏好是否与问题匹配，大多数时候直接决定了算法能否取得好的性能.</p><p>继续回头看图1.3，假设学习算法$\mathcal{L}$</p><p><strong>未完待续…..</strong></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;机器学习中的归纳偏好。&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器学习" scheme="https://fly97.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>奥卡姆剃刀和没有免费的午餐定理</title>
    <link href="https://fly97.cn/p/%E5%A5%A5%E5%8D%A1%E5%A7%86%E5%89%83%E5%88%80%E5%92%8C%E6%B2%A1%E6%9C%89%E5%85%8D%E8%B4%B9%E7%9A%84%E5%8D%88%E9%A4%90%E5%AE%9A%E7%90%86.html"/>
    <id>https://fly97.cn/p/%E5%A5%A5%E5%8D%A1%E5%A7%86%E5%89%83%E5%88%80%E5%92%8C%E6%B2%A1%E6%9C%89%E5%85%8D%E8%B4%B9%E7%9A%84%E5%8D%88%E9%A4%90%E5%AE%9A%E7%90%86.html</id>
    <published>2020-08-06T13:50:00.000Z</published>
    <updated>2020-08-06T13:50:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文原载于<a href="https://imlogm.github.io/">https://imlogm.github.io</a>，转载请注明出处！</p><p><strong>摘要</strong>：“奥卡姆剃刀”和“没有免费的午餐”是机器学习中两个很基本的原则和定理。由于名字有点怪，所以初学者可能在理解上陷入误区。本文试图用简洁易懂的方式解释这两个原则和定理，并告诉大家它们的名字是怎么来的。</p><p><strong>关键字</strong>：机器学习, 奥卡姆剃刀, 没有免费的午餐</p><a id="more"></a><p>“奥卡姆剃刀”和“没有免费的午餐”是机器学习中两个很基本的原则和定理，很多书都会提到它们来提升逼格。不过，烦就烦在它们的名字取的有些不好理解，初学者望文生义就容易错误理解。其实，了解了它们名字的由来，这两个原则和定理是很容易想明白的，也不用去纠结如何证明它们，因为它们更接近哲学思想，而不是你会在实际项目中用到的公式。</p><h4 id="奥卡姆剃刀（Occam’s-razor）"><a href="#奥卡姆剃刀（Occam’s-razor）" class="headerlink" title="奥卡姆剃刀（Occam’s razor）"></a>奥卡姆剃刀（Occam’s razor）</h4><p>“奥卡姆剃刀”其实并不是机器学习领域产生的定理，事实上，它是哲学领域的一个思想。这个思想说起来也很简单，7个字，<code>“简单的是最好的”</code>。</p><p>相信大家不难理解这个哲学思想，比如在数学领域，大多数数学家认为“好的公式应当是简洁明了的”，就是“奥卡姆剃刀”的体现。</p><p>这个思想我能理解，但为什么叫这么奇怪的名字？容易想到，“奥卡姆”是提出这个思想的人的名字；至于为什么叫“剃刀”是因为这个思想的提出，对封建旧思想来说是把锋利的剃刀，狠狠地剃除教会的旧思想。（具体是如何剃除旧思想的就不展开了）</p><p>那这个思想是怎么应用在机器学习领域的呢？用下图就可以概括：</p><img src="https://ftp.fly97.cn/image/overfit.png" style="zoom:80%;" align="center"/><p>了解机器学习的同学不难看出，上图表示的是过拟合问题，不了解的同学也不必担心，可以把上图想象成用曲线拟合几个点。</p><p>那么问题来了，上图中，哪种拟合方式是比较好的呢？相信大多数人都会选择左小图的拟合方式。机器学习领域也通常认为左小图是比较好的，原因就是“奥卡姆剃刀”的思想，“简单的是最好的”。</p><p>有些敢于挑战权威的同学可能会反驳，“怎么证明图1左小图是更简单的呢？我可以认为右小图更简单”。是的，这个问题周志华的西瓜书中也有提到，其实是没有办法说明哪种更简单。这也是哲学问题的通病，难以联系到实际中，往往会有多种解读。</p><p>不过我们不用去纠结怎样才算“简单”，只要明白这个词是什么意思就可以了。</p><p>可能还会有同学反驳，“我同意左小图是简单的，但万一实际情况中右小图才是更符合结果的拟合方式呢？”。这个想法也是对的，我们无法证明实际情况一定是左小图的拟合方式最好。这也就是下面“没有免费的午餐”定理要说明的。</p><h4 id="“没有免费的午餐”定理（no-free-lunch-NFL）"><a href="#“没有免费的午餐”定理（no-free-lunch-NFL）" class="headerlink" title="“没有免费的午餐”定理（no free lunch, NFL）"></a>“没有免费的午餐”定理（no free lunch, NFL）</h4><p>这个定理的名字乍一看很唬人，也有很多初学者因为这个名字陷入了误区。我们可以先把名字放在一边，先看定理的内容。</p><p>这个定理证明起来很复杂，一长串的数学公式，但说明白其实只要一句话，<code>“没有一种机器学习算法是适用于所有情况的”</code>。</p><p>这也符合我们的直觉。举个例子吧，比如上图，假设上图的左小图是机器算法A给出的拟合曲线，上图的右小图是机器算法B给出的拟合曲线。我们就一定能说机器算法A比机器算法B更好吗？或者说左小图的拟合曲线一定比右小图更符合实际情况吗？都不能。“没有免费的午餐”定理证明了对于所有机器学习问题，机器算法A更好与机器算法B更好的概率是一样的。<code>更一般地说，对于所有机器学习问题，任何一种算法（包括瞎猜）的期望效果都是一样的</code>。</p><p>那我们还学个啥？既然任何算法的期望效果和瞎猜一样，我们为什么还要学？</p><p>注意，这个定理有个前提：“对于所有机器学习问题，且所有问题同等重要”。而我们实际情况不是这样，我们在实际中往往更关心的是一个特定的机器学习问题，对于特定的问题，特定的机器学习算法效果自然比瞎猜更好。还是上图的例子，虽然“没有免费的午餐”定理告诉我们：我们不能预计到底是左小图拟合更好还是右小图拟合更好，但聪明的你一定能想到：是好是坏，代入到具体问题中检验一下不就知道了。</p><p>这个定理本质上就是告诉我们不要奢望能找到一种算法对所有问题都适用。这么说来，这个定理其实有点废话，因为我们面对的总是一个特定的问题，而不是所有问题。</p><p>但是这个定理其实揭示了一个哲学思想，“有得必有失”，某一个机器学习算法在某个领域好用，在另外一个领域就有可能不好用，瞎猜在一些情况下不好用，但在某个特定的问题上会很好用。就像能量守恒定理，这里的能量增加，另外一边的能量就会减少。天上掉馅饼被你捡到了，这个时刻你很幸运，但是之后你就会倒霉。</p><p>理解了上面一段话，也就明白了这个定理为什么取这么奇怪的名字。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文原载于&lt;a href=&quot;https://imlogm.github.io/&quot;&gt;https://imlogm.github.io&lt;/a&gt;，转载请注明出处！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;：“奥卡姆剃刀”和“没有免费的午餐”是机器学习中两个很基本的原则和定理。由于名字有点怪，所以初学者可能在理解上陷入误区。本文试图用简洁易懂的方式解释这两个原则和定理，并告诉大家它们的名字是怎么来的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键字&lt;/strong&gt;：机器学习, 奥卡姆剃刀, 没有免费的午餐&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器学习" scheme="https://fly97.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习基本概念02</title>
    <link href="https://fly97.cn/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B502.html"/>
    <id>https://fly97.cn/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B502.html</id>
    <published>2020-08-06T10:30:00.000Z</published>
    <updated>2020-08-06T10:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习中的假设空间。</p><a id="more"></a><h4 id="假设空间"><a href="#假设空间" class="headerlink" title="假设空间"></a>假设空间</h4><p>​    <strong>归纳(induction)和演绎(deduction)**是科学推理的两大基本手段。归纳是从特殊到一般的”泛化”(generalization)过程。即从具体的事实归结出一般性规律；演绎则是从一般到特殊的”特化”(specialization)过程，即从基础原理推演出具体状况。例如，在数学公理系统中，基于一组公理和推理规则推导出与之相恰的定理，这是演绎；而”从样例中学习”显然是一个归纳的过程，因此亦称为</strong>“归纳学习”(inductive learning)**</p><p>​    归纳学习有狭义和广义之分，广义的归纳学习大体相当于从样例中学习，而狭义的归纳学习则要求从训练数据中学得概念(concept),因此亦称为**”概念学习”或”概念形成”**.概念学习技术目前应用、研究都比较少，因为要学得泛化性能好而且语义明确的概念实在是太难了，现实常用的技术大多数产生”黑箱”模型.然而，对概念学习有所理解，有助于理解机器学习的一些基础思想。</p><p>​    概念学习中最基本的是<strong>布尔概念学习</strong>，即对”是””不是”这样的可表示为0/1布尔值的目标概念的学习.举一个简单的例子，假定我们获得了这样的一个训练数据集：</p><img src="https://ftp.fly97.cn/image/image-20200806202414852.png" alt="image-20200806202414852" style="zoom:50%;" /><p>​    这里要学习的目标是”好瓜”，暂且假设”好瓜”可由”色泽””根蒂””敲声”这三个因素完全确定，换言之，只要某个瓜的三个属性取值明确了，我们就能判断出它是不是好瓜，于是，我们学到的将是”好瓜是某种色泽、某种根蒂、某种敲声的瓜”这样的概念，用布尔表达式写出来则是**”好瓜$ \leftrightarrow $(色泽=?)^(根蒂=?)^(敲声=?)”**，这里”?”表示尚未确定的取值，而我们的任务就是通过对上表的训练集进行学习，把”?”确定下来.</p><p>​    读者可能马上发现，上表第一行：**”(色泽=青绿)^(根蒂=蜷缩)^(敲声=浊响)”<strong>不就是好瓜吗？是的，但这是一个已见过的瓜，不要忘记学习的目的是</strong>“泛化”<strong>，即通过对训练集中的瓜的学习以获得对没见过瓜进行判断的能力.如果仅仅把训练集中的瓜”记住”，今后再见到一模一样的瓜当然可以判断，但是，对没见过的瓜，例如</strong>“(色泽=浅白)^(根蒂=蜷缩)^(敲声=浊响)”**怎么办呢？</p><p>​    我们可以把学习过程看作一个在<strong>所有假设组成的空间</strong>中进行搜索的过程，搜索目标是找到与训练集*<em>“匹配(fit)”<strong>的假设，即能够将训练集中的瓜判断正确的假设.假设的表示一旦确定，假设空间及其规模大小就确定了.这里我们的假设空间由形如</strong>“(色泽=?)^(根蒂=?)^(敲声=?)”**的可能取值所形成的假设组成.例如色泽有”青绿””乌黑””浅白”这三种可能取值；还需考虑到，也许色泽无论取什么值都合适，我们用通配符”</em>“来表示，例如*<em>“好瓜$ \leftrightarrow $(色泽=\</em>)^(根蒂=蜷缩)^(敲声=浊响)”**，即”好瓜是根蒂蜷缩、敲声浊响的瓜，什么色泽都行”.此外，还需要考虑极端情况，有可能”好瓜”这个概念根本不成立，世界上没有”好瓜”这种东西，我们用$ \emptyset $表示这个假设。这样，若”色泽””根蒂””敲声”分别有3、2、2种可能取值，则我们面临的假设空间规模大小为$4 \times 3 \times 3+1=37$.下图直观地显示了这个西瓜空间假设问题。</p><blockquote><p>这里我们假定训练样本不含噪声，而且不考虑”非青绿”这样的$\not\subset A$操作，由于训练集包含正例，因此$ \emptyset $假设自然不出现。</p></blockquote><p><img src="https://ftp.fly97.cn/image/image-20200806202019247.png" alt="image-20200806202019247"></p><p>​    可以有许多策略对这个假设空间进行搜索，例如自顶向下、从一般到特殊，或是自底向上、从特殊到一般，搜索过程种可以不断删除与正例不一致的假设和(或)与反例一致的假设.最终将会获得**与训练集一致(即对所有训练样本能够进行正确判断)**的假设，这就是我们学习的结果。</p><blockquote><p>有很多可能的选择，如在路径上自顶向下与自底向上同时进行，在操作上只删除与正例不一致的假设等。</p></blockquote><p>​    需注意的是，现实问题种我们常面临很大的假设空间，但学习过程是基于有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在一个<strong>与训练集一致的”假设集合”**，我们称之为</strong>“版本空间”(version space).**例如，在西瓜问题中，与表1.1训练集所对应的版本空间如图1.2所示.</p><img src="https://ftp.fly97.cn/image/image-20200806203152041.png" alt="image-20200806203152041"  />]]></content>
    
    
    <summary type="html">&lt;p&gt;机器学习中的假设空间。&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器学习" scheme="https://fly97.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习基本概念01</title>
    <link href="https://fly97.cn/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B501.html"/>
    <id>https://fly97.cn/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B501.html</id>
    <published>2020-08-05T10:30:00.000Z</published>
    <updated>2020-08-05T10:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>为了理解深度学习，先了解一下机器学习的基本术语。</p><a id="more"></a><h4 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h4><p>机器学习的经典定义：<strong>利用经验改善系统自身的性能。</strong></p><p>机器学习所研究的主要内容，是关于在计算机上从数据中产生的模型的算法，即学习算法。有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型。在面对新的情况时，模型会给我们相应的判断。</p><blockquote><p>【Mitchell,1997】给出了一个更形式化的定义：假设用<em>P</em>来评估计算机程序在某任务类<em>T</em>上的性能，若一个程序通过利用经验<em>E</em>在<em>T</em>中任务上获得了性能改善，则我们就说关于<em>T</em>和<em>P</em>，该程序对<em>E</em>进行了学习。</p></blockquote><p>模型：泛指从数据中学到的结果。有文献用”模型”指全局性结果(例如一颗决策树)，而用”模式”指局部性结果(例如一条规则).</p><h4 id="基本术语"><a href="#基本术语" class="headerlink" title="基本术语"></a>基本术语</h4><p>要进行机器学习，首先要有数据。假定收集了一批关于西瓜的数据，例如（色泽=青绿；根蒂=蜷缩；敲声=浊响），（色泽=乌黑；根蒂=稍蜷；敲声=沉闷），（色泽=浅白；根蒂=硬挺；敲声=清脆），······，每对括号内是一条记录，”=”的意思是”取值为”.</p><p>记录数据的集合称为一个**”数据集”(data set)<strong>，其中每条记录是关于一个事件和对象的叙述，称为一个</strong>“示例”（instance)或”样本”（sample）**。</p><p>反应事件或对象在某方面的表现或者性质的事项，例如”色泽”，”根蒂”，”敲声”，称为**”属性”（attribute)或”特征”（feature）**。</p><p>属性上的取值，例如”青绿”，”乌黑”，称为**”属性值”（attribute value）<strong>。属性张成的空间称为</strong>“属性空间”（attribute space）、”样本空间”（sample space）或”输入空间”**。</p><p>例如，我们把”色泽”、”根蒂”和”敲声”作为三个坐标轴，则他们张成的一个用于描述西瓜的三维空间，每个西瓜都可在这个空间找到他们自己的坐标位置。由于空间中的每个点对应一个坐标向量，因此也把一个示例称为一个**”特征向量”（feature vector）**。</p><p>​    一般地，令$ \small D=\{x_1,x_2,…,x_m\} $表示包含$m$个实例的数据集，每个实例由$d$个属性描述(例如上面的西瓜数据使用了3个属性)，则每个实例$x_i=\{x_{i1},x_{i2},…,x_{id}\}$是$d$维样本空间 $\chi$ 中一个向量，$x_i \in \chi$，其中$x_{ij}$是第$j$个属性上的取值(例如上述第3个西瓜在第二个属性上的属性是”硬挺”)，$d$称为样本$x_i$的**”维数”(dimensionality)**.</p><p>​    从数据中学得模型的过程称为**”学习”（learning）<strong>或者</strong>“训练”（training）<strong>，这个过程通过执行某个学习算法来完成。训练过程使用的数据称为</strong>“训练数据”（training data）<strong>，其中每个样本称为一个</strong>“训练样本”（training sample)<strong>，训练样本组成的集合称为</strong>“训练集”（training set）<strong>。学得模型对应了关于数据的某种潜在的规律，因此亦称</strong>“假设”（hypothesis）<strong>；这种潜在规律本身，则称为</strong>“真相”或”真实”(ground-truth)**，学习过程就是为了找出或逼近真相。</p><blockquote><p>训练样本亦称为”训练示例”（training instance）或者”训练例”。</p><p>学习算法通常由参数需要设置，使用不同的参数值和(或)训练数据，将产生不同的结果。</p><p>有时将模型称为”学习器”（learner)，可看作学习算法在给定数据和参数空间上的实例化。</p></blockquote><p>​    如果希望学得一个能够判断没剖开的是不是”好瓜”的模型，仅有前面的示例数据显然是不够的，要建立这样的关于**”预测”（prediction）<strong>的模型，需要获得训练样本的”结果”信息，例如”((色泽=青绿；根蒂=蜷缩；敲声=浊响)，好瓜)”。这里关于实例结果的信息，例如”好瓜”，称为</strong>“标记”（label）<strong>；拥有了标记信息的示例，则成为</strong>“样例”（example)<strong>。一般地，用$(x_i,y_i)$表示第$i$个样例，其中$y_i \in Y$是示例$x_i$的标记，$Y$ 是所有标记的集合，亦称为</strong>“标记空间”(label space)或”输出空间”**。</p><p>​    若我们欲预测的是离散值，例如”好瓜”、”坏瓜”，此类任务被称为**”分类”(classification)<strong>；若欲预测的是连续值，例如西瓜成熟度0.95，0.37，此类学习任务称为</strong>“回归”(regression)<strong>。对涉及两个类别的</strong>“二分类”(binary classification)<strong>任务，通常称其中一个类为</strong>“正类”(positive class)<strong>，另一个类称为</strong>“反类”(negative class)<strong>;涉及多个类别时，则成为</strong>“多分类”(multi-class classification)**任务。一般地，预测任务是希望通过对训练集${(x_1,y_1),(x_2,y_2),…,(x_m,y_m)}$进行学习，建立一个从输入空间$X$到输出空间$Y$的映射$f : X \to Y$。对于二分类任务，通常令$Y=\{-1,+1\}$或$\{0,1\}$；对多分类任务，$|Y|&gt;2$；对于回归任务，$Y=R$，$R$为实数集。</p><p>​    学得模型后，使用其进行预测的过程称为**”测试”(testing)<strong>，被预测的样本称为</strong>“测试样本”(testing sample)**。例如在学得$f$后，对测试例$x$可得到其预测标记$y=f(x)$。</p><p>​    还可以对西瓜做**”聚类”(clustering)<strong>，即将训练集中的西瓜分成若干组，每组称为一个</strong>“簇”（cluster）**；这些自动形成得簇可能对应一些潜在得概念划分，例如”浅色瓜”、”深色瓜”，甚至”本地瓜”、”外地瓜”。这样的学习过程有助于哦我们了解数据内在得规律，能为更深入地分析数据建立基础。需说明的是，在聚类分析中，”浅色瓜，本地瓜”这样得概念我们实现是不知道的，而且学习过程中使用的训练样本通常不拥有标记信息。</p><p>​    根据训练数据是否拥有标记信息，学习任务可大致分为两大类：**”监督学习”(supervised learning)<strong>和</strong>“无监督学习”(unsupervised learning)**。分类和回归是监督学习的代表，而聚类是无监督学习的代表。</p><p>​    需要注意的是，机器学习的目标是使学得的模型能很好地适用于”新样本”，而不是仅仅在训练样本上工作得很好；即便对聚类这样得无监督学习任务，我们也希望学得簇划分能适用于没在训练集中出现的样本。学得模型适用于新样本的能力，称为**”泛化”(generalization)能力**。具有强泛化能力的模型能够很好的适用于整个样本空间。尽管训练集通常只是样本空间的一个很小的采样，我们仍希望它能很好的反映出样本空间的特性，否则就很难再期望在训练集上学得的模型能在整个样本空间上都工作得很好。</p><blockquote><p>通常假设样本空间中全体样本服从一个未知**”分布”(distribution)<strong>$\small D$，我们获得的每个样本都是</strong>“独立同分布”(independent and identically distributed，简称$i.i.d$)**。一般而言，训练样本越多，我们得到得关于$D$的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;为了理解深度学习，先了解一下机器学习的基本术语。&lt;/p&gt;</summary>
    
    
    
    
    <category term="机器学习" scheme="https://fly97.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Docker的网络模式</title>
    <link href="https://fly97.cn/p/Docker%E7%9A%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F.html"/>
    <id>https://fly97.cn/p/Docker%E7%9A%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F.html</id>
    <published>2020-08-01T11:00:00.000Z</published>
    <updated>2020-08-01T11:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><code>docker</code>目前支持以下5种网络模式：</p><p>使用<code>docker run</code> 创建 <code>Docker</code> 容器时，可以用 <code>--network</code> 选项指定容器的网络模式。</p><a id="more"></a><h3 id="host模式"><a href="#host模式" class="headerlink" title="host模式"></a>host模式</h3><p>​    使用 <code>--netrork=host</code> 指定。与宿主机共享网络，此时容器没有使用网络的namespace，宿主机的所有设备，如Dbus会暴露到容器中，因此存在安全隐患。容器将不会虚拟出自己的网卡，配置自己的 IP 等，而是使用宿主机的 IP 和端口。</p><h3 id="container模式"><a href="#container模式" class="headerlink" title="container模式"></a>container模式</h3><p>使用 <code>--network=container:NAME or ID</code> 指定。指定与某个容器实例共享网络。这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。</p><h3 id="none模式"><a href="#none模式" class="headerlink" title="none模式"></a>none模式</h3><p>使用 <code>--network=none</code> 指定。不设置网络，相当于容器内没有配置网卡，用户可以手动配置。</p><h3 id="bridge模式-（默认设置）"><a href="#bridge模式-（默认设置）" class="headerlink" title="bridge模式 （默认设置）"></a>bridge模式 （默认设置）</h3><p>使用 <code>--network=bridge</code> 指定，默认设置。</p><p>bridge 模式是 Docker 默认的网络设置，此模式会为每一个容器分配 Network Namespace、设置 IP 等，并将一个主机上的 Docker 容器连接到一个虚拟网桥上。</p><p>当 Docker server 启动时，会在主机上创建一个名为 docker0 的虚拟网桥，此主机上启动的 Docker 容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。</p><p>接下来就要为容器分配 IP 了，Docker 会从 RFC1918 所定义的私有 IP 网段中，选择一个和宿主机不同的IP地址和子网分配给 docker0，连接到 docker0 的容器就从这个子网中选择一个未占用的 IP 使用。如一般 Docker 会使用 172.17.0.0/16 这个网段，并将 172.17.42.1/16 分配给 docker0 网桥（在主机上使用 ifconfig 命令是可以看到 docker0 的，可以认为它是网桥的管理接口，在宿主机上作为一块虚拟网卡使用）</p><p>当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。</p><p><strong>默认是桥接模式，网络地址为172.17.0.0/16，同一主机的容器实例能够通信，但不能跨主机通信。</strong></p><h3 id="自定义模式"><a href="#自定义模式" class="headerlink" title="自定义模式"></a>自定义模式</h3><p>使用自定义网络，可以使用docker network create创建，并且默认支持多种网络驱动，用户可以自由创建桥接网络或者overlay网络。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;docker&lt;/code&gt;目前支持以下5种网络模式：&lt;/p&gt;
&lt;p&gt;使用&lt;code&gt;docker run&lt;/code&gt; 创建 &lt;code&gt;Docker&lt;/code&gt; 容器时，可以用 &lt;code&gt;--network&lt;/code&gt; 选项指定容器的网络模式。&lt;/p&gt;</summary>
    
    
    
    
    <category term="docker" scheme="https://fly97.cn/tags/docker/"/>
    
  </entry>
  
</feed>
